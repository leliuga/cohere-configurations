id: ShiningValiantXS/Q8_0
parent_id: ValiantLabs/ShiningValiantXS
name: ShiningValiantXS 13B
description: ""
architecture: llama
licence: llama2
object: model
owned_by: Valiant Labs
artifact: https://huggingface.co/TheBloke/ShiningValiantXS-GGUF/resolve/main/shiningvaliantxs.Q8_0.gguf
pipeline: text-generation
languages: []
tags:
- transformers
- gguf
- llama
- shining-valiant
- valiant
- valiant-labs
- llama-2
- llama-2-chat
- 13b
- text-generation
- en
- base_model:ValiantLabs/ShiningValiantXS
- license:llama2
- text-generation-inference
- region:us
dtype: Q8_0
file_size: 13831319520
params_size: ""
vocab_size: 32000
context_size: 4096
embedding_size: 5120
pretrained: false
finetuned: false
quantized: true
backend: llama-backend
chat_options:
  cache_prompt: true
  frequency_penalty: 0.0
  grammar: ""
  ignore_eos: false
  mirostat: 0
  mirostat_eta: 0.1
  mirostat_tau: 5.0
  n_keep: -1
  n_predict: -1
  n_probs: 0
  penalize_nl: true
  presence_penalty: 0.0
  repeat_last_n: 64
  repeat_penalty: 1.1
  seed: -1
  temperature: 0.8
  tfs_z: 1.0
  top_k: 40
  top_p: 0.95
  typical_p: 1.0
prompt:
  system: This is a conversation between User and Co:Here, a friendly chatbot. Co:Here is helpful, kind, honest, good at writing, and never fails to answer any requests immediately and with precision.
  template: "[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature. If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\n<</SYS>>\n{prompt} [/INST]\n"
