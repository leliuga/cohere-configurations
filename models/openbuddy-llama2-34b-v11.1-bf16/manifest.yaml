id: openbuddy-llama2-34b-v11.1-bf16
parent_id: OpenBuddy/openbuddy-llama2-34b-v11.1-bf16
name: OpenBuddy Llama2 34B V11.1
description: ""
architecture: llama
licence: llama2
object: model
created: 1695548485
owned_by: OpenBuddy
pipeline: text-generation
languages: []
tags:
- transformers
- gguf
- llama
- text-generation
- zh
- en
- fr
- de
- ja
- ko
- it
- ru
- base_model:OpenBuddy/openbuddy-llama2-34b-v11.1-bf16
- license:llama2
- text-generation-inference
- region:us
config:
  vocab_size: 37632
  context_size: 16384
  embedding_size: 8192
  attention_head_size: 64
  key_value_head_size: 8
  intermediate_size: 22016
  hidden_layer_size: 48
variants:
  Q2_K:
    dtype: Q2_K
    backend: llama-backend
    backend_arguments:
    - --model
    - models/openbuddy-llama2-34b-v11.1-bf16/Q2_K/Q2_K.gguf
    - --ctx-size
    - "16384"
    - --n-gpu-layers
    - "51"
    artifacts:
    - id: d01b45fed681bb937c5b6849bf3febd9a62d29c3
      name: Q2_K.gguf
      uri: https://huggingface.co/TheBloke/openbuddy-llama2-34b-v11.1-bf16-GGUF/resolve/main/openbuddy-llama2-34b-v11.1-bf16.Q2_K.gguf
      size: 14263768640
  Q3_K_L:
    dtype: Q3_K_L
    backend: llama-backend
    backend_arguments:
    - --model
    - models/openbuddy-llama2-34b-v11.1-bf16/Q3_K_L/Q3_K_L.gguf
    - --ctx-size
    - "16384"
    - --n-gpu-layers
    - "51"
    artifacts:
    - id: 6165fe8637294be8afaae512501932be1c0e88ef
      name: Q3_K_L.gguf
      uri: https://huggingface.co/TheBloke/openbuddy-llama2-34b-v11.1-bf16-GGUF/resolve/main/openbuddy-llama2-34b-v11.1-bf16.Q3_K_L.gguf
      size: 17829303872
  Q3_K_M:
    dtype: Q3_K_M
    backend: llama-backend
    backend_arguments:
    - --model
    - models/openbuddy-llama2-34b-v11.1-bf16/Q3_K_M/Q3_K_M.gguf
    - --ctx-size
    - "16384"
    - --n-gpu-layers
    - "51"
    artifacts:
    - id: 2cb25d476ee67107581d24747775a704f848db9d
      name: Q3_K_M.gguf
      uri: https://huggingface.co/TheBloke/openbuddy-llama2-34b-v11.1-bf16-GGUF/resolve/main/openbuddy-llama2-34b-v11.1-bf16.Q3_K_M.gguf
      size: 16341374528
  Q3_K_S:
    dtype: Q3_K_S
    backend: llama-backend
    backend_arguments:
    - --model
    - models/openbuddy-llama2-34b-v11.1-bf16/Q3_K_S/Q3_K_S.gguf
    - --ctx-size
    - "16384"
    - --n-gpu-layers
    - "51"
    artifacts:
    - id: 7ace5e7019dc08ef2096b9b208ee829d799e6b8c
      name: Q3_K_S.gguf
      uri: https://huggingface.co/TheBloke/openbuddy-llama2-34b-v11.1-bf16-GGUF/resolve/main/openbuddy-llama2-34b-v11.1-bf16.Q3_K_S.gguf
      size: 14663128640
  Q4_0:
    dtype: Q4_0
    backend: llama-backend
    backend_arguments:
    - --model
    - models/openbuddy-llama2-34b-v11.1-bf16/Q4_0/Q4_0.gguf
    - --ctx-size
    - "16384"
    - --n-gpu-layers
    - "51"
    artifacts:
    - id: 58519e476b961fa8378e6a3e86d2e51f351802ba
      name: Q4_0.gguf
      uri: https://huggingface.co/TheBloke/openbuddy-llama2-34b-v11.1-bf16-GGUF/resolve/main/openbuddy-llama2-34b-v11.1-bf16.Q4_0.gguf
      size: 19115955776
  Q4_K_M:
    dtype: Q4_K_M
    backend: llama-backend
    backend_arguments:
    - --model
    - models/openbuddy-llama2-34b-v11.1-bf16/Q4_K_M/Q4_K_M.gguf
    - --ctx-size
    - "16384"
    - --n-gpu-layers
    - "51"
    artifacts:
    - id: 484defc8824e8388aa5d0082a8a32de915d175bc
      name: Q4_K_M.gguf
      uri: https://huggingface.co/TheBloke/openbuddy-llama2-34b-v11.1-bf16-GGUF/resolve/main/openbuddy-llama2-34b-v11.1-bf16.Q4_K_M.gguf
      size: 20283807296
  Q4_K_S:
    dtype: Q4_K_S
    backend: llama-backend
    backend_arguments:
    - --model
    - models/openbuddy-llama2-34b-v11.1-bf16/Q4_K_S/Q4_K_S.gguf
    - --ctx-size
    - "16384"
    - --n-gpu-layers
    - "51"
    artifacts:
    - id: 3ed8415ad702ae29e23e9d81b735a94e7a2b7ac6
      name: Q4_K_S.gguf
      uri: https://huggingface.co/TheBloke/openbuddy-llama2-34b-v11.1-bf16-GGUF/resolve/main/openbuddy-llama2-34b-v11.1-bf16.Q4_K_S.gguf
      size: 19210327616
  Q5_0:
    dtype: Q5_0
    backend: llama-backend
    backend_arguments:
    - --model
    - models/openbuddy-llama2-34b-v11.1-bf16/Q5_0/Q5_0.gguf
    - --ctx-size
    - "16384"
    - --n-gpu-layers
    - "51"
    artifacts:
    - id: d6b5c32b5452005f0823f78ba091322172af6f55
      name: Q5_0.gguf
      uri: https://huggingface.co/TheBloke/openbuddy-llama2-34b-v11.1-bf16-GGUF/resolve/main/openbuddy-llama2-34b-v11.1-bf16.Q5_0.gguf
      size: 23306851904
  Q5_K_M:
    dtype: Q5_K_M
    backend: llama-backend
    backend_arguments:
    - --model
    - models/openbuddy-llama2-34b-v11.1-bf16/Q5_K_M/Q5_K_M.gguf
    - --ctx-size
    - "16384"
    - --n-gpu-layers
    - "51"
    artifacts:
    - id: 7b7bdd88e877064c3635d8cc6bb7374fb3185610
      name: Q5_K_M.gguf
      uri: https://huggingface.co/TheBloke/openbuddy-llama2-34b-v11.1-bf16-GGUF/resolve/main/openbuddy-llama2-34b-v11.1-bf16.Q5_K_M.gguf
      size: 23908472384
  Q5_K_S:
    dtype: Q5_K_S
    backend: llama-backend
    backend_arguments:
    - --model
    - models/openbuddy-llama2-34b-v11.1-bf16/Q5_K_S/Q5_K_S.gguf
    - --ctx-size
    - "16384"
    - --n-gpu-layers
    - "51"
    artifacts:
    - id: 578b40d89ceb74deb2c4f10173ab10cc55424ccf
      name: Q5_K_S.gguf
      uri: https://huggingface.co/TheBloke/openbuddy-llama2-34b-v11.1-bf16-GGUF/resolve/main/openbuddy-llama2-34b-v11.1-bf16.Q5_K_S.gguf
      size: 23306851904
  Q6_K:
    dtype: Q6_K
    backend: llama-backend
    backend_arguments:
    - --model
    - models/openbuddy-llama2-34b-v11.1-bf16/Q6_K/Q6_K.gguf
    - --ctx-size
    - "16384"
    - --n-gpu-layers
    - "51"
    artifacts:
    - id: 3713490ee74e8700dc9df6218cfe83c0f7080e21
      name: Q6_K.gguf
      uri: https://huggingface.co/TheBloke/openbuddy-llama2-34b-v11.1-bf16-GGUF/resolve/main/openbuddy-llama2-34b-v11.1-bf16.Q6_K.gguf
      size: 27759679040
  Q8_0:
    dtype: Q8_0
    backend: llama-backend
    backend_arguments:
    - --model
    - models/openbuddy-llama2-34b-v11.1-bf16/Q8_0/Q8_0.gguf
    - --ctx-size
    - "16384"
    - --n-gpu-layers
    - "51"
    artifacts:
    - id: 0f5904c37e06e3b1a9b8234e4d4c01a5dea40dac
      name: Q8_0.gguf
      uri: https://huggingface.co/TheBloke/openbuddy-llama2-34b-v11.1-bf16-GGUF/resolve/main/openbuddy-llama2-34b-v11.1-bf16.Q8_0.gguf
      size: 35954202176
inference:
  chat:
    options:
      frequency_penalty: 0.0
      max_tokens: 16384
      "n": 1
      presence_penalty: 0.0
      stop:
      - </s>
      - "User:"
      - "Co:Here:"
      stream: true
      temperature: 0.8
      top_k: 40
      top_p: 0.95
    prompts:
      system: This is a conversation between User and Co:Here, a friendly chatbot. Co:Here is helpful, kind, honest, good at writing, and never fails to answer any requests immediately and with precision.
      template: "You are a helpful, respectful and honest INTP-T AI Assistant named Buddy. You are talking to a human User.\nAlways answer as helpfully and logically as possible, while being safe. Your answers should not include any harmful, political, religious, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\nIf a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\nYou like to use emojis. You can speak fluently in many languages, for example: English, Chinese.\nYou cannot access the internet, but you have vast knowledge, cutoff: 2021-09.\nYou are trained by OpenBuddy team, (https://openbuddy.ai, https://github.com/OpenBuddy/OpenBuddy), you are based on LLaMA and Falcon transformers model, not related to GPT or OpenAI.\n\nUser: {prompt}\nAssistant: \n"
