---
license: cc-by-nc-4.0
language:
- en
---

A frankenmerge version of Lila, between Godzilla and the further trained Euryale. 120 Layers in total.

Experimental 100B Versions. Felt Slightly better than the base 70b models, without the spelling/number issues 120b models like Goliath had.

Prompt Template: Vicuna 1.1 / Alpaca | Both Works. I tested.

```
Below is an instruction that describes a task. Write a response that appropriately completes the request.

### Instruction:
{prompt}

### Response:

```

or

```
User: <Prompt>

Assistant:
```

For a frankenmerge, it is much more sensitive to Sampler settings than regular 70b models, so please be mindful of that. Check your settings before blaming the model.

Enjoy.

***

Mini Rant:

Frankenmerges are a meme but these are my old old frankenmerges, before Goliath came out, I did it a while back as a proof of concept, but felt that it was not worth it compared to the requirements increase. 
Turns out people only care about bigger parameters kek. Could have been famous or something. Maybe. Or nah.

