id: Tess-34B-v1.4
parent_id: migtissera/Tess-34B-v1.4
name: Tess 34B v1.4
description: ""
architecture: llama
licence: other
object: model
created: 1701873319
owned_by: Migel Tissera
pipeline: ""
languages: []
tags:
- transformers
- gguf
- yi
- base_model:migtissera/Tess-34B-v1.4
- license:other
- region:us
config:
  vocab_size: 64002
  context_size: 200000
  embedding_size: 7168
  attention_head_size: 56
  key_value_head_size: 8
  intermediate_size: 20480
  hidden_layer_size: 60
variants:
  Q2_K:
    dtype: Q2_K
    backend: llama-backend
    backend_arguments:
    - --model
    - models/Tess-34B-v1.4/Q2_K/Q2_K.gguf
    - --ctx-size
    - "200000"
    - --n-gpu-layers
    - "63"
    artifacts:
    - id: 59d28c19c4e20e4aafbe4aadcb42b8d58168064d
      name: Q2_K.gguf
      uri: https://huggingface.co/TheBloke/Tess-34B-v1.4-GGUF/resolve/main/tess-34b-v1.4.Q2_K.gguf
      size: 14555891840
  Q3_K_L:
    dtype: Q3_K_L
    backend: llama-backend
    backend_arguments:
    - --model
    - models/Tess-34B-v1.4/Q3_K_L/Q3_K_L.gguf
    - --ctx-size
    - "200000"
    - --n-gpu-layers
    - "63"
    artifacts:
    - id: 38dfbb3886af420c82991ea442e07e402ec2e257
      name: Q3_K_L.gguf
      uri: https://huggingface.co/TheBloke/Tess-34B-v1.4-GGUF/resolve/main/tess-34b-v1.4.Q3_K_L.gguf
      size: 18139463232
  Q3_K_M:
    dtype: Q3_K_M
    backend: llama-backend
    backend_arguments:
    - --model
    - models/Tess-34B-v1.4/Q3_K_M/Q3_K_M.gguf
    - --ctx-size
    - "200000"
    - --n-gpu-layers
    - "63"
    artifacts:
    - id: 8120018b331d6a71085df2d74bbdd1dc796aea83
      name: Q3_K_M.gguf
      uri: https://huggingface.co/TheBloke/Tess-34B-v1.4-GGUF/resolve/main/tess-34b-v1.4.Q3_K_M.gguf
      size: 16636591680
  Q3_K_S:
    dtype: Q3_K_S
    backend: llama-backend
    backend_arguments:
    - --model
    - models/Tess-34B-v1.4/Q3_K_S/Q3_K_S.gguf
    - --ctx-size
    - "200000"
    - --n-gpu-layers
    - "63"
    artifacts:
    - id: 2b732a838da330377be93dd3ded7f1ab2ae908fb
      name: Q3_K_S.gguf
      uri: https://huggingface.co/TheBloke/Tess-34B-v1.4-GGUF/resolve/main/tess-34b-v1.4.Q3_K_S.gguf
      size: 14960311872
  Q4_0:
    dtype: Q4_0
    backend: llama-backend
    backend_arguments:
    - --model
    - models/Tess-34B-v1.4/Q4_0/Q4_0.gguf
    - --ctx-size
    - "200000"
    - --n-gpu-layers
    - "63"
    artifacts:
    - id: 00ab80da533b7fdd8b109db3db697f406175da2c
      name: Q4_0.gguf
      uri: https://huggingface.co/TheBloke/Tess-34B-v1.4-GGUF/resolve/main/tess-34b-v1.4.Q4_0.gguf
      size: 19466548640
  Q4_K_M:
    dtype: Q4_K_M
    backend: llama-backend
    backend_arguments:
    - --model
    - models/Tess-34B-v1.4/Q4_K_M/Q4_K_M.gguf
    - --ctx-size
    - "200000"
    - --n-gpu-layers
    - "63"
    artifacts:
    - id: 10ccf2a7f417c2ad2dfb427f7ebeff78fc3ad825
      name: Q4_K_M.gguf
      uri: https://huggingface.co/TheBloke/Tess-34B-v1.4-GGUF/resolve/main/tess-34b-v1.4.Q4_K_M.gguf
      size: 20658730400
  Q4_K_S:
    dtype: Q4_K_S
    backend: llama-backend
    backend_arguments:
    - --model
    - models/Tess-34B-v1.4/Q4_K_S/Q4_K_S.gguf
    - --ctx-size
    - "200000"
    - --n-gpu-layers
    - "63"
    artifacts:
    - id: f284541f2d707f41a1143d82c6e59031f291f675
      name: Q4_K_S.gguf
      uri: https://huggingface.co/TheBloke/Tess-34B-v1.4-GGUF/resolve/main/tess-34b-v1.4.Q4_K_S.gguf
      size: 19543618976
  Q5_0:
    dtype: Q5_0
    backend: llama-backend
    backend_arguments:
    - --model
    - models/Tess-34B-v1.4/Q5_0/Q5_0.gguf
    - --ctx-size
    - "200000"
    - --n-gpu-layers
    - "63"
    artifacts:
    - id: 46e4ebdc8d4818ad8952a0b877f8b6e135de2429
      name: Q5_0.gguf
      uri: https://huggingface.co/TheBloke/Tess-34B-v1.4-GGUF/resolve/main/tess-34b-v1.4.Q5_0.gguf
      size: 23707712672
  Q5_K_M:
    dtype: Q5_K_M
    backend: llama-backend
    backend_arguments:
    - --model
    - models/Tess-34B-v1.4/Q5_K_M/Q5_K_M.gguf
    - --ctx-size
    - "200000"
    - --n-gpu-layers
    - "63"
    artifacts:
    - id: 431d54586cb1e9f53ea0b0d553fd4dc04f2abf71
      name: Q5_K_M.gguf
      uri: https://huggingface.co/TheBloke/Tess-34B-v1.4-GGUF/resolve/main/tess-34b-v1.4.Q5_K_M.gguf
      size: 24321866912
  Q5_K_S:
    dtype: Q5_K_S
    backend: llama-backend
    backend_arguments:
    - --model
    - models/Tess-34B-v1.4/Q5_K_S/Q5_K_S.gguf
    - --ctx-size
    - "200000"
    - --n-gpu-layers
    - "63"
    artifacts:
    - id: 3399c434d049cfdb69b392dea68895d8f09c296b
      name: Q5_K_S.gguf
      uri: https://huggingface.co/TheBloke/Tess-34B-v1.4-GGUF/resolve/main/tess-34b-v1.4.Q5_K_S.gguf
      size: 23707712672
  Q6_K:
    dtype: Q6_K
    backend: llama-backend
    backend_arguments:
    - --model
    - models/Tess-34B-v1.4/Q6_K/Q6_K.gguf
    - --ctx-size
    - "200000"
    - --n-gpu-layers
    - "63"
    artifacts:
    - id: a4e5f612895f40ec7179c0979eeb5c7c1fc6da38
      name: Q6_K.gguf
      uri: https://huggingface.co/TheBloke/Tess-34B-v1.4-GGUF/resolve/main/tess-34b-v1.4.Q6_K.gguf
      size: 28213949472
  Q8_0:
    dtype: Q8_0
    backend: llama-backend
    backend_arguments:
    - --model
    - models/Tess-34B-v1.4/Q8_0/Q8_0.gguf
    - --ctx-size
    - "200000"
    - --n-gpu-layers
    - "63"
    artifacts:
    - id: 16c494f86b7c43dc6cceeb518a12bfbda7ef350d
      name: Q8_0.gguf
      uri: https://huggingface.co/TheBloke/Tess-34B-v1.4-GGUF/resolve/main/tess-34b-v1.4.Q8_0.gguf
      size: 36542312224
inference:
  chat:
    options:
      frequency_penalty: 0.0
      max_tokens: 200000
      "n": 1
      presence_penalty: 0.0
      stop:
      - </s>
      - "User:"
      - "Co:Here:"
      stream: true
      temperature: 0.8
      top_k: 40
      top_p: 0.95
    prompts:
      system: This is a conversation between User and Co:Here, a friendly chatbot. Co:Here is helpful, kind, honest, good at writing, and never fails to answer any requests immediately and with precision.
      template: "SYSTEM: {system_message}\nUSER: {prompt}\nASSISTANT:\n"
