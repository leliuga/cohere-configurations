id: Amethyst-13B-Mistral/Q3_K_L
parent_id: Undi95/Amethyst-13B-Mistral
name: Amethyst 13B Mistral
description: ""
architecture: llama
licence: cc-by-nc-4.0
object: model
owned_by: Undi
dsn: https://huggingface.co/TheBloke/Amethyst-13B-Mistral-GGUF/resolve/main/amethyst-13b-mistral.Q3_K_L.gguf
pipeline: ""
languages: []
tags:
- transformers
- llama
- not-for-all-audiences
- nsfw
- base_model:Undi95/Amethyst-13B-Mistral
- license:cc-by-nc-4.0
- text-generation-inference
- region:us
dtype: Q3_K_L
file_size: 6929559520
params_size: ""
vocab_size: 32000
context_size: 4096
embedding_size: 5120
pretrained: false
finetuned: false
quantized: true
backend_options:
  batch-size: "2048"
  cont-batching: ""
  ctx-size: "2048"
  mlock: ""
  n-gpu-layers: "43"
  name: llama-backend
  numa: ""
  parallel: "2"
  threads: "12"
  timeout: "600"
predict_options:
  cache_prompt: "true"
  frequency_penalty: "0.0"
  grammar: ""
  ignore_eos: "false"
  mirostat: "0"
  mirostat_eta: "0.1"
  mirostat_tau: "5.0"
  n_keep: "-1"
  n_predict: "-1"
  n_probs: "0"
  penalize_nl: "true"
  presence_penalty: "0.0"
  repeat_last_n: "64"
  repeat_penalty: "1.1"
  seed: "-1"
  stream: "true"
  temperature: "0.8"
  tfs_z: "1.0"
  top_k: "40"
  top_p: "0.95"
  typical_p: "1.0"
prompt_options:
  system: This is a conversation between User and Co:Here, a friendly chatbot. Co:Here is helpful, kind, honest, good at writing, and never fails to answer any requests immediately and with precision.
  template: "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n"
