id: mamba-2.8b-hf
parent_id: state-spaces/mamba-2.8b-hf
name: mamba-2.8b-hf
description: ""
architecture: mamba
licence: apache-2.0
object: model
created: 1710538614
owned_by: State Space Models
pipeline: text-generation
languages: []
tags:
- transformers
- gguf
- mamba
- text-generation
- base_model:state-spaces/mamba-2.8b-hf
- license:apache-2.0
- autotrain_compatible
- region:us
config:
  vocab_size: 50280
  context_size: 0
  embedding_size: 2560
  attention_head_size: 0
  key_value_head_size: 0
  intermediate_size: 5120
  hidden_layer_size: 64
variants:
  Q2_K:
    dtype: Q2_K
    backend: llama-backend
    backend_arguments:
    - --model
    - models/mamba-2.8b-hf/Q2_K/Q2_K.gguf
    artifacts:
    - id: 5ac81c0a2584ad0f67157c36a8a4bee8f8b2cac4
      name: Q2_K.gguf
      uri: https://huggingface.co/leliuga/mamba-2.8b-hf-GGUF/resolve/main/mamba-2.8b-hf.Q2_K.gguf
      size: 1425331264
  Q3_K_L:
    dtype: Q3_K_L
    backend: llama-backend
    backend_arguments:
    - --model
    - models/mamba-2.8b-hf/Q3_K_L/Q3_K_L.gguf
    artifacts:
    - id: f7baa86e78d8f52653f9e930354eb7bcb849fff5
      name: Q3_K_L.gguf
      uri: https://huggingface.co/leliuga/mamba-2.8b-hf-GGUF/resolve/main/mamba-2.8b-hf.Q3_K_L.gguf
      size: 1680921664
  Q3_K_M:
    dtype: Q3_K_M
    backend: llama-backend
    backend_arguments:
    - --model
    - models/mamba-2.8b-hf/Q3_K_M/Q3_K_M.gguf
    artifacts:
    - id: 4d656d744d9835d0070dc422985614b42f13d8d7
      name: Q3_K_M.gguf
      uri: https://huggingface.co/leliuga/mamba-2.8b-hf-GGUF/resolve/main/mamba-2.8b-hf.Q3_K_M.gguf
      size: 1680921664
  Q3_K_S:
    dtype: Q3_K_S
    backend: llama-backend
    backend_arguments:
    - --model
    - models/mamba-2.8b-hf/Q3_K_S/Q3_K_S.gguf
    artifacts:
    - id: 6dbc2e0d22cd4d5a59c31c56cb7275c87707453a
      name: Q3_K_S.gguf
      uri: https://huggingface.co/leliuga/mamba-2.8b-hf-GGUF/resolve/main/mamba-2.8b-hf.Q3_K_S.gguf
      size: 1680921664
  Q4_0:
    dtype: Q4_0
    backend: llama-backend
    backend_arguments:
    - --model
    - models/mamba-2.8b-hf/Q4_0/Q4_0.gguf
    artifacts:
    - id: 9d48ac6e2db077a133ca6b8b2855b3a469bc0d98
      name: Q4_0.gguf
      uri: https://huggingface.co/leliuga/mamba-2.8b-hf-GGUF/resolve/main/mamba-2.8b-hf.Q4_0.gguf
      size: 2015155264
  Q4_K_M:
    dtype: Q4_K_M
    backend: llama-backend
    backend_arguments:
    - --model
    - models/mamba-2.8b-hf/Q4_K_M/Q4_K_M.gguf
    artifacts:
    - id: 2c7f03f388160434dfc26829eb080d136db7a77c
      name: Q4_K_M.gguf
      uri: https://huggingface.co/leliuga/mamba-2.8b-hf-GGUF/resolve/main/mamba-2.8b-hf.Q4_K_M.gguf
      size: 2015155264
  Q4_K_S:
    dtype: Q4_K_S
    backend: llama-backend
    backend_arguments:
    - --model
    - models/mamba-2.8b-hf/Q4_K_S/Q4_K_S.gguf
    artifacts:
    - id: 05c26bbba07477376bd0036527d72340410e542c
      name: Q4_K_S.gguf
      uri: https://huggingface.co/leliuga/mamba-2.8b-hf-GGUF/resolve/main/mamba-2.8b-hf.Q4_K_S.gguf
      size: 2015155264
  Q5_0:
    dtype: Q5_0
    backend: llama-backend
    backend_arguments:
    - --model
    - models/mamba-2.8b-hf/Q5_0/Q5_0.gguf
    artifacts:
    - id: 4dc9fda333502a4e1cb90c68ff2d5abc6c9c6a3b
      name: Q5_0.gguf
      uri: https://huggingface.co/leliuga/mamba-2.8b-hf-GGUF/resolve/main/mamba-2.8b-hf.Q5_0.gguf
      size: 2329728064
  Q5_K_M:
    dtype: Q5_K_M
    backend: llama-backend
    backend_arguments:
    - --model
    - models/mamba-2.8b-hf/Q5_K_M/Q5_K_M.gguf
    artifacts:
    - id: a292719cc41d077835d2d70eec0cfb351d475bb0
      name: Q5_K_M.gguf
      uri: https://huggingface.co/leliuga/mamba-2.8b-hf-GGUF/resolve/main/mamba-2.8b-hf.Q5_K_M.gguf
      size: 2329728064
  Q5_K_S:
    dtype: Q5_K_S
    backend: llama-backend
    backend_arguments:
    - --model
    - models/mamba-2.8b-hf/Q5_K_S/Q5_K_S.gguf
    artifacts:
    - id: 79622a3f724d859301db8b2ea48a090f5982ea93
      name: Q5_K_S.gguf
      uri: https://huggingface.co/leliuga/mamba-2.8b-hf-GGUF/resolve/main/mamba-2.8b-hf.Q5_K_S.gguf
      size: 2329728064
  Q6_K:
    dtype: Q6_K
    backend: llama-backend
    backend_arguments:
    - --model
    - models/mamba-2.8b-hf/Q6_K/Q6_K.gguf
    artifacts:
    - id: 0732200245e65cdcf9124b504aaec78a88e12333
      name: Q6_K.gguf
      uri: https://huggingface.co/leliuga/mamba-2.8b-hf-GGUF/resolve/main/mamba-2.8b-hf.Q6_K.gguf
      size: 2663961664
  Q8_0:
    dtype: Q8_0
    backend: llama-backend
    backend_arguments:
    - --model
    - models/mamba-2.8b-hf/Q8_0/Q8_0.gguf
    artifacts:
    - id: 8b82a1fa386a5f1a5c341987b5d9597317746814
      name: Q8_0.gguf
      uri: https://huggingface.co/leliuga/mamba-2.8b-hf-GGUF/resolve/main/mamba-2.8b-hf.Q8_0.gguf
      size: 3304620064
inference:
  chat:
    options:
      frequency_penalty: 0.0
      max_tokens: 4096
      "n": 1
      presence_penalty: 0.0
      stop:
      - </s>
      - "User:"
      - "Co:Here:"
      stream: true
      temperature: 0.8
      top_k: 40
      top_p: 0.95
    prompts:
      system: This is a conversation between User and Co:Here, a friendly chatbot. Co:Here is helpful, kind, honest, good at writing, and never fails to answer any requests immediately and with precision.
      template: ""
