id: manticore-13b-chat-pyg/Q5_K_S
parent_id: openaccess-ai-collective/manticore-13b-chat-pyg
name: Manticore 13B Chat Pyg
description: ""
architecture: llama
licence: other
object: model
owned_by: Open Access AI Collective
artifact: https://huggingface.co/TheBloke/manticore-13b-chat-pyg-GGUF/resolve/main/manticore-13b-chat-pyg.Q5_K_S.gguf
pipeline: text-generation
languages: []
tags:
- transformers
- gguf
- llama
- text-generation
- en
- dataset:anon8231489123/ShareGPT_Vicuna_unfiltered
- dataset:ehartford/wizard_vicuna_70k_unfiltered
- dataset:ehartford/WizardLM_alpaca_evol_instruct_70k_unfiltered
- dataset:QingyiSi/Alpaca-CoT
- dataset:teknium/GPT4-LLM-Cleaned
- dataset:teknium/GPTeacher-General-Instruct
- dataset:metaeval/ScienceQA_text_only
- dataset:hellaswag
- dataset:openai/summarize_from_feedback
- dataset:riddle_sense
- dataset:gsm8k
- dataset:ewof/code-alpaca-instruct-unfiltered
- base_model:openaccess-ai-collective/manticore-13b-chat-pyg
- license:other
- has_space
- text-generation-inference
- region:us
dtype: Q5_K_S
file_size: 8972285888
params_size: ""
vocab_size: 32000
context_size: 2048
embedding_size: 5120
pretrained: false
finetuned: false
quantized: true
backend: llama-backend
chat_options:
  cache_prompt: true
  frequency_penalty: 0.0
  grammar: ""
  ignore_eos: false
  mirostat: 0
  mirostat_eta: 0.1
  mirostat_tau: 5.0
  n_keep: -1
  n_predict: -1
  n_probs: 0
  penalize_nl: true
  presence_penalty: 0.0
  repeat_last_n: 64
  repeat_penalty: 1.1
  seed: -1
  temperature: 0.8
  tfs_z: 1.0
  top_k: 40
  top_p: 0.95
  typical_p: 1.0
prompt:
  system: This is a conversation between User and Co:Here, a friendly chatbot. Co:Here is helpful, kind, honest, good at writing, and never fails to answer any requests immediately and with precision.
  template: "A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions. USER: {prompt} ASSISTANT:\n"
