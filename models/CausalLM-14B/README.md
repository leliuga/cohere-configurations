---
license: wtfpl
datasets:
- JosephusCheung/GuanacoDataset
- Open-Orca/OpenOrca
- stingning/ultrachat
- meta-math/MetaMathQA
- liuhaotian/LLaVA-Instruct-150K
- jondurbin/airoboros-3.1
- WizardLM/WizardLM_evol_instruct_V2_196k
- RyokoAI/ShareGPT52K
- RyokoAI/Fandom23K
- milashkaarshif/MoeGirlPedia_wikitext_raw_archive
- wikipedia
- wiki_lingua
- fnlp/moss-003-sft-data
- garage-bAInd/Open-Platypus
- LDJnr/Puffin
- openbmb/llava_zh
- BAAI/COIG
- TigerResearch/tigerbot-zhihu-zh-10k
- liwu/MNBVC
- teknium/openhermes
language:
- en
- zh
pipeline_tag: text-generation
tags:
- llama
- llama2
- qwen
- causallm
---
![](https://huggingface.co/JosephusCheung/tmp/resolve/main/14.17b.png)

*Image drawn by GPT-4 DALLÂ·E 3* **TL;DR: Perhaps better than all existing models < 70B, in most quantitative evaluations...**

# CausalLM 14B - Fully Compatible with Meta LLaMA 2
Use the transformers library that does not require remote/external code to load the model, AutoModelForCausalLM and AutoTokenizer (or manually specify LlamaForCausalLM to load LM, GPT2Tokenizer to load Tokenizer), and model quantization is fully compatible with GGUF (llama.cpp), GPTQ, and AWQ.

**News: SOTA chat model of its size on ðŸ¤— Open LLM Leaderboard**

# Recent Updates: [DPO-Î± Version](https://huggingface.co/CausalLM/14B-DPO-alpha) outperforms Zephyr-Î² in MT-Bench

# Friendly reminder: If your VRAM is insufficient, you should use the 7B model instead of the quantized version.
Compared to the quantized versions, the 7B version and the 14B version demonstrate a high level of consistency.

**llama.cpp GGUF models**
GPT2Tokenizer fixed by [Kerfuffle](https://github.com/KerfuffleV2) on [https://github.com/ggerganov/llama.cpp/pull/3743](https://github.com/ggerganov/llama.cpp/pull/3743), new models are now reuploaded.

Thanks TheBloke for GGUF quants: [https://huggingface.co/TheBloke/CausalLM-14B-GGUF](https://huggingface.co/TheBloke/CausalLM-14B-GGUF)

**Caution:** Unofficial GPTQ and AWQ models may have issues as they use Wikitext for calibration, while this model has undergone considerable training on a synthesized Wikipedia conversation dataset.

It is not recommended to use any form of quantization, but rather to use smaller-sized models, as the 7B and 14B versions have high consistency. However, if you do use model quantization, please use GGUF.

# Read Me:

Also see [7B Version](https://huggingface.co/CausalLM/7B)

This model was trained based on the model weights of Qwen (and LLaMA2 was used, yes, for calculating some initial weights), you may also need to comply with the commercial use restrictions of these two models depending on the situation. The training process utilized a model structure that was identical to LLaMA2, using the same attention calculation method as the original MHA LLaMA2 models, and no additional scaling applied to the Rotary Positional Encoding (RoPE).

We manually curated a SFT dataset of 1.3B tokens for training, utilizing open source datasets from Hugging Face. For most of these sentences, we performed manual or synthetic rewrites and generated alternate language versions using larger language models. Additionally, we conducted augmented text training using carefully selected entries from Wikipedia, as well as featured entries from Fandom and filtered entries from Moegirlpedia. In order to strike a balance between efficiency and quality, 100% of the data used for training was synthetic data, no direct use of text from the internet or original texts from publicly available datasets was employed for fine-tuning.

The 7B version of the model is a distilled version of the 14B model, specifically designed for speculative sampling. Therefore, it is important to exercise caution when directly using the model, as it may produce hallucinations or unreliable outputs.

Please note that the model was trained on unfiltered internet data. Since we do not have the capacity to vet all of it, there may be a substantial amount of objectionable content, pornography, violence, and offensive language present that we are unable to remove. Therefore, you will still need to complete your own checks on the model's safety and filter keywords in the output. Due to computational resource constraints, we are presently unable to implement RLHF for the model's ethics and safety, nor training on SFT samples that refuse to answer certain questions for restrictive fine-tuning.

Bonus: The model underwent some fine-tuning on the prompt format introduced in LLaVA1.5 that is unrelated to image attention calculation. Therefore, aligning the ViT Projection module with frozen LM under visual instructions would enable rapid implementation of effective multimodal capabilities.

## PROMPT FORMAT:
[chatml](https://github.com/openai/openai-python/blob/main/chatml.md)

**System Prompt must not be empty!**

## MMLU:
stem ACC: 64.19 

Humanities ACC: 61.40 

other ACC: 71.64 

social ACC: 75.37 

**AVERAGE ACC:67.36** (Outperforms ALL models under 70B, very close to those best 70B fine-tunes)


## CEval (Val):
STEM ACC: 66.71 

Social Science ACC: 85.10 

Humanities ACC: 76.68 

Other ACC: 70.23 

Hard ACC:54.71 

**AVERAGE ACC:73.10** (Outperforms Qwen-14B, and GPT-4)

## GSM8K

**Zero-shot ACC 0.7012888551933283** (Outperforms MetaMath-13B, Qwen-14B)

## AlpacaEval Leaderboard
|              | win_rate | standard_error | n_wins | n_wins_base | n_draws | n_total | mode      | avg_length |
| ------------ | -------- | -------------- | ------ | ----------- | ------- | ------- | --------- | ---------- |
| causallm-14b | **88.26087** | 1.116333       | 705    | 89          | 11      | 805     | community | 1391       |

Win rate **88.26%**	on [AlpacaEval Leaderboard](https://tatsu-lab.github.io/alpaca_eval/) [view raw](https://github.com/tatsu-lab/alpaca_eval/blob/3a47dcd81c56f6a8e6a5711f2754013919fbe90a/results/causallm-14b/model_outputs.json)

## MT-Behch on DPO Version
| Model                     | MT-Bench     |
| ------------------------- | ------------ |
| GPT-4                     | 8.99         |
| GPT-3.5-Turbo             | 7.94         |
|                           |              |
| Zephyr-7b-Î² (Overfitting) | 7.34         |
| Zephyr-7b-Î±               | 6.88         |
|                           |              |
| **[CausalLM/14B-DPO-Î±](https://huggingface.co/CausalLM/14B-DPO-alpha)**    | **7.618868** |
| **[CausalLM/7B-DPO-Î±](https://huggingface.co/CausalLM/7B-DPO-alpha)**     | **7.038125** |

## Other languages
We are currently unable to produce accurate benchmark templates for non-QA tasks (languages other than English and Chinese). However, we will be working on other language versions of the QA-Task challenge in the near future.
### Japanese Benchmark
|         Task         |Version| Metric |Value |   |Stderr|
|----------------------|------:|--------|-----:|---|-----:|
|jcommonsenseqa-1.1-0.6|    1.1|acc     |0.8213|Â±  |0.0115|

*JCommonsenseQA benchmark result is very, very close to [Japanese Stable LM Gamma 7B (83.47)](https://github.com/Stability-AI/lm-evaluation-harness/tree/jp-stable), current SOTA Japanese LM. However, our model was not trained on a particularly large amount of text in Japanese. This seems to reflect the cross-language transferability of metalinguistics.*

## ðŸ¤— Open LLM Leaderboard
SOTA chat model of its size on ðŸ¤— Open LLM Leaderboard.

![leaderboard](https://huggingface.co/JosephusCheung/tmp/resolve/main/leaderboard.png)

# å› æžœè¯­è¨€æ¨¡åž‹ 14B - ä¸Ž Meta LLaMA 2 å®Œå…¨å…¼å®¹
ä½¿ç”¨æ— éœ€è¿œç¨‹/å¤–éƒ¨ä»£ç çš„transformersåº“åŠ è½½æ¨¡åž‹ï¼ŒAutoModelForCausalLMå’ŒAutoTokenizerï¼ˆæˆ–è€…æ‰‹åŠ¨æŒ‡å®šLlamaForCausalLMåŠ è½½LMï¼Œ GPT2TokenizeråŠ è½½Tokenizerï¼‰ï¼Œå¹¶ä¸”æ¨¡åž‹é‡åŒ–ä¸ŽGGUFï¼ˆllama.cppï¼‰ã€GPTQã€AWQå®Œå…¨å…¼å®¹ã€‚

# æ–°æ¶ˆæ¯ï¼šðŸ¤— Open LLM æŽ’è¡Œæ¦œä¸ŠåŒå°ºå¯¸çš„èŠå¤©æ¨¡åž‹ä¸­è¯„åˆ†æœ€é«˜

# æœ€è¿‘æ›´æ–°: [DPO-Î± Version](https://huggingface.co/CausalLM/14B-DPO-alpha) åœ¨ MT-Bench è¶…è¿‡ Zephyr-Î²

# å‹æƒ…æç¤ºï¼šå¦‚æžœæ‚¨çš„æ˜¾å­˜ä¸è¶³ï¼Œæ‚¨åº”è¯¥ä½¿ç”¨7Bæ¨¡åž‹è€Œä¸æ˜¯é‡åŒ–ç‰ˆæœ¬ã€‚
ä¸Žé‡åŒ–ç‰ˆæœ¬ç›¸æ¯”ï¼Œ7B ç‰ˆæœ¬å’Œ 14B ç‰ˆæœ¬å…·æœ‰é«˜åº¦çš„ä¸€è‡´æ€§ã€‚

**llama.cpp GGUF models**
GPT2Tokenizer æ”¯æŒç”± [Kerfuffle](https://github.com/KerfuffleV2) ä¿®å¤äºŽ [https://github.com/ggerganov/llama.cpp/pull/3743](https://github.com/ggerganov/llama.cpp/pull/3743)ï¼Œæ–°æ¨¡åž‹ç¨åŽä¸Šä¼ ã€‚

æ„Ÿè°¢ TheBloke åˆ¶ä½œ GGUF ç‰ˆæœ¬é‡åŒ–æ¨¡åž‹: [https://huggingface.co/TheBloke/CausalLM-14B-GGUF](https://huggingface.co/TheBloke/CausalLM-14B-GGUF)

**æ³¨æ„ï¼š** éžå®˜æ–¹ GPTQ å’Œ AWQ æ¨¡åž‹å¯èƒ½å­˜åœ¨é—®é¢˜ï¼Œå› ä¸ºå®ƒä»¬ä½¿ç”¨ Wikitext è¿›è¡Œæ ¡å‡†ï¼Œè€Œè¯¥æ¨¡åž‹å·²ç»åœ¨åˆæˆçš„ Wikipedia å¯¹è¯æ•°æ®é›†ä¸Šç»è¿‡äº†å¤§é‡çš„è®­ç»ƒã€‚

ä¸å»ºè®®ä½¿ç”¨ä»»ä½•å½¢å¼çš„é‡åŒ–ï¼Œè€Œæ˜¯ä½¿ç”¨è¾ƒå°å°ºå¯¸çš„æ¨¡åž‹ï¼Œå› ä¸º7Bå’Œ14Bç‰ˆæœ¬å…·æœ‰è¾ƒé«˜çš„ä¸€è‡´æ€§ã€‚ ä½†æ˜¯ï¼Œå¦‚æžœæ‚¨ç¡®å®žä½¿ç”¨æ¨¡åž‹é‡åŒ–ï¼Œè¯·ä½¿ç”¨ GGUFã€‚

## è¯·è¯»æˆ‘ï¼š

å¦è¯·å‚é˜…[7Bç‰ˆæœ¬](https://huggingface.co/CausalLM/7B)

è¯¥æ¨¡åž‹æ˜¯åŸºäºŽQwençš„æƒé‡ï¼ˆå¹¶ä½¿ç”¨äº†LLaMA2æƒé‡ï¼Œæ˜¯çš„ï¼Œç”¨äºŽè®¡ç®—ä¸€äº›æƒé‡åˆå§‹åŒ–ï¼‰ï¼Œæ‚¨æ ¹æ®æƒ…å†µå¯èƒ½è¿˜éœ€è¦éµå®ˆè¿™ä¸¤ä¸ªæ¨¡åž‹çš„å•†ä¸šä½¿ç”¨é™åˆ¶ã€‚è®­ç»ƒè¿‡ç¨‹ä¸­ä½¿ç”¨äº†ä¸ŽLLaMA2ç›¸åŒçš„æ¨¡åž‹ç»“æž„ï¼Œä½¿ç”¨åŽŸå§‹MHA LLaMA2æ¨¡åž‹çš„ç›¸åŒæ³¨æ„åŠ›è®¡ç®—æ–¹æ³•ï¼Œå¯¹æ—‹è½¬ä½ç½®ç¼–ç ï¼ˆRoPEï¼‰æ²¡æœ‰è¿›è¡Œé¢å¤–çš„ç¼©æ”¾ã€‚

æˆ‘ä»¬æ‰‹åŠ¨ç­›é€‰äº†ä¸€ä¸ªåŒ…å«13äº¿ä¸ªæ ‡è®°çš„SFTæ•°æ®é›†è¿›è¡Œè®­ç»ƒï¼Œåˆ©ç”¨äº†Hugging Faceçš„å¼€æºæ•°æ®é›†ã€‚å¯¹äºŽå¤§å¤šæ•°å¥å­ï¼Œæˆ‘ä»¬è¿›è¡Œäº†æ‰‹åŠ¨æˆ–åˆæˆæ”¹å†™ï¼Œå¹¶ä½¿ç”¨æ›´å¤§çš„è¯­è¨€æ¨¡åž‹ç”Ÿæˆäº†å…¶ä»–è¯­è¨€ç‰ˆæœ¬ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜ä½¿ç”¨äº†ç²¾å¿ƒæŒ‘é€‰çš„æ¥è‡ªç»´åŸºç™¾ç§‘çš„æ¡ç›®ã€æ¥è‡ªFandomçš„ç²¾é€‰æ¡ç›®ä»¥åŠæ¥è‡ªèŒå¨˜ç™¾ç§‘çš„è¿‡æ»¤æ¡ç›®è¿›è¡Œå¢žå¼ºæ–‡æœ¬è®­ç»ƒã€‚ä¸ºäº†åœ¨æ•ˆçŽ‡å’Œè´¨é‡ä¹‹é—´å–å¾—å¹³è¡¡ï¼Œè®­ç»ƒæ‰€ä½¿ç”¨çš„100%æ•°æ®éƒ½æ˜¯åˆæˆæ•°æ®ï¼Œæ²¡æœ‰ç›´æŽ¥ä½¿ç”¨æ¥è‡ªäº’è”ç½‘æˆ–å…¬å¼€å¯ç”¨æ•°æ®é›†çš„åŽŸå§‹æ–‡æœ¬è¿›è¡Œå¾®è°ƒã€‚

7Bç‰ˆæœ¬çš„æ¨¡åž‹æ˜¯14Bæ¨¡åž‹çš„ç²¾ç®€ç‰ˆæœ¬ï¼Œä¸“é—¨è®¾è®¡ç”¨äºŽæŽ¨æµ‹æŠ½æ ·ã€‚å› æ­¤ï¼Œåœ¨ç›´æŽ¥ä½¿ç”¨æ¨¡åž‹æ—¶ï¼Œéœ€è¦è°¨æ…Žè¡Œäº‹ï¼Œå› ä¸ºå®ƒå¯èƒ½ä¼šäº§ç”Ÿå¹»è§‰æˆ–ä¸å¯é çš„è¾“å‡ºã€‚

è¯·æ³¨æ„ï¼Œæ¨¡åž‹æ˜¯åœ¨æœªç»è¿‡æ»¤çš„äº’è”ç½‘æ•°æ®ä¸Šè¿›è¡Œè®­ç»ƒçš„ã€‚ç”±äºŽæˆ‘ä»¬æ— æ³•å®¡æ ¸æ‰€æœ‰æ•°æ®ï¼Œå¯èƒ½ä¼šå‡ºçŽ°å¤§é‡ä¸è‰¯å†…å®¹ã€è‰²æƒ…ã€æš´åŠ›å’Œå†’çŠ¯æ€§è¯­è¨€ï¼Œæˆ‘ä»¬æ— æ³•åˆ é™¤è¿™äº›å†…å®¹ã€‚å› æ­¤ï¼Œæ‚¨ä»ç„¶éœ€è¦å¯¹æ¨¡åž‹çš„å®‰å…¨æ€§è¿›è¡Œè‡ªå·±çš„æ£€æŸ¥ï¼Œå¹¶å¯¹è¾“å‡ºä¸­çš„å…³é”®è¯è¿›è¡Œè¿‡æ»¤ã€‚ç”±äºŽè®¡ç®—èµ„æºçš„é™åˆ¶ï¼Œæˆ‘ä»¬ç›®å‰æ— æ³•ä¸ºæ¨¡åž‹çš„ä¼¦ç†å’Œå®‰å…¨å®žæ–½RLHFï¼Œä¹Ÿæ— æ³•å¯¹æ‹’ç»å›žç­”æŸäº›é—®é¢˜çš„SFTæ ·æœ¬è¿›è¡Œè®­ç»ƒä»¥è¿›è¡Œé™åˆ¶æ€§å¾®è°ƒã€‚

é¢å¤–å¥–åŠ±ï¼šæ¨¡åž‹åœ¨LLaVA1.5ä¸­å¼•å…¥çš„æç¤ºæ ¼å¼ä¸Šè¿›è¡Œäº†ä¸€äº›å¾®è°ƒï¼Œä¸Žå›¾åƒæ³¨æ„åŠ›è®¡ç®—æ— å…³ã€‚å› æ­¤ï¼Œå°†ViTæŠ•å½±æ¨¡å—ä¸Žå†»ç»“çš„LMå¯¹é½ï¼Œå¹¶æ ¹æ®è§†è§‰æŒ‡ä»¤å®žæ–½å¿«é€Ÿå®žçŽ°æœ‰æ•ˆçš„å¤šæ¨¡æ€èƒ½åŠ›ã€‚

## æç¤ºæ ¼å¼ï¼š
[chatml](https://github.com/openai/openai-python/blob/main/chatml.md)

**ç³»ç»Ÿæç¤ºä¸èƒ½ä¸ºç©ºï¼**


## MMLUï¼š
STEMå‡†ç¡®çŽ‡ï¼š64.19 

äººæ–‡åŠè‰ºæœ¯å­¦ç§‘å‡†ç¡®çŽ‡ï¼š61.40 

å…¶ä»–å­¦ç§‘å‡†ç¡®çŽ‡ï¼š71.64 

ç¤¾ä¼šå­¦ç§‘å‡†ç¡®çŽ‡ï¼š75.37 

**å¹³å‡å‡†ç¡®çŽ‡ï¼š67.36**ï¼ˆè¶…è¿‡æ‰€æœ‰70Bä»¥ä¸‹çš„æ¨¡åž‹ï¼Œéžå¸¸æŽ¥è¿‘æœ€ä½³70Bå¾®è°ƒæ¨¡åž‹ï¼‰

## CEvalï¼ˆéªŒè¯é›†ï¼‰ï¼š
STEMå‡†ç¡®çŽ‡ï¼š66.71 

ç¤¾ä¼šç§‘å­¦å‡†ç¡®çŽ‡ï¼š85.10 

äººæ–‡å­¦ç§‘å‡†ç¡®çŽ‡ï¼š76.68 

å…¶ä»–å­¦ç§‘å‡†ç¡®çŽ‡ï¼š70.23 

å›°éš¾å‡†ç¡®çŽ‡ï¼š54.71 

**å¹³å‡å‡†ç¡®çŽ‡ï¼š73.10**ï¼ˆè¶…è¿‡Qwen-14Bå’ŒGPT-4ï¼‰

## GSM8K

**é›¶æ ·æœ¬å‡†ç¡®çŽ‡0.7012888551933283**ï¼ˆè¶…è¿‡MetaMath-13Bå’ŒQwen-14Bï¼‰

## AlpacaEval Leaderboard
|              | win_rate | standard_error | n_wins | n_wins_base | n_draws | n_total | mode      | avg_length |
| ------------ | -------- | -------------- | ------ | ----------- | ------- | ------- | --------- | ---------- |
| causallm-14b | **88.26087** | 1.116333       | 705    | 89          | 11      | 805     | community | 1391       |

åœ¨ [AlpacaEval Leaderboard](https://tatsu-lab.github.io/alpaca_eval/) èƒœçŽ‡ **88.26%** [view raw](https://github.com/tatsu-lab/alpaca_eval/blob/3a47dcd81c56f6a8e6a5711f2754013919fbe90a/results/causallm-14b/model_outputs.json)

## DPO ç‰ˆæœ¬çš„ MT-Behch
| Model                     | MT-Bench     |
| ------------------------- | ------------ |
| GPT-4                     | 8.99         |
| GPT-3.5-Turbo             | 7.94         |
|                           |              |
| Zephyr-7b-Î² (Overfitting) | 7.34         |
| Zephyr-7b-Î±               | 6.88         |
|                           |              |
| **[CausalLM/14B-DPO-Î±](https://huggingface.co/CausalLM/14B-DPO-alpha)**    | **7.618868** |
| **[CausalLM/7B-DPO-Î±](https://huggingface.co/CausalLM/7B-DPO-alpha)**     | **7.038125** |

## å…¶ä»–è¯­è¨€
æˆ‘ä»¬ç›®å‰æ— æ³•ä¸ºéž QA ä»»åŠ¡ï¼ˆè‹±è¯­å’Œä¸­æ–‡ä»¥å¤–çš„è¯­è¨€ï¼‰ç”Ÿæˆå‡†ç¡®çš„åŸºå‡†æ¨¡æ¿ã€‚ ä¸è¿‡ï¼Œæˆ‘ä»¬å°†åœ¨ä¸ä¹…çš„å°†æ¥å¼€å‘å…¶ä»–è¯­è¨€ç‰ˆæœ¬çš„ QA-Task æŒ‘æˆ˜ã€‚
### æ—¥æ–‡åŸºå‡†
|         Task         |Version| Metric |Value |   |Stderr|
|----------------------|------:|--------|-----:|---|-----:|
|jcommonsenseqa-1.1-0.6|    1.1|acc     |0.8213|Â±  |0.0115|

*JCommonsenseQA åŸºå‡†æµ‹è¯•ç»“æžœéžå¸¸éžå¸¸æŽ¥è¿‘ [Japanese Stable LM Gamma 7B (83.47)](https://github.com/Stability-AI/lm-evaluation-harness/tree/jp-stable)ï¼Œå½“å‰ SOTA æ—¥æ–‡ LM ã€‚ç„¶è€Œï¼Œæˆ‘ä»¬çš„æ¨¡åž‹å¹¶æœªåœ¨æ—¥æ–‡ä¸Šè¿›è¡Œç‰¹åˆ«çš„å¤§é‡æ–‡æœ¬è®­ç»ƒã€‚è¿™ä¼¼ä¹Žèƒ½ä½“çŽ°å…ƒè¯­è¨€çš„è·¨è¯­è¨€è¿ç§»èƒ½åŠ›ã€‚*

## ðŸ¤— Open LLM æŽ’è¡Œæ¦œ
ðŸ¤— Open LLM æŽ’è¡Œæ¦œä¸ŠåŒå°ºå¯¸çš„èŠå¤©æ¨¡åž‹ä¸­è¯„åˆ†æœ€é«˜

![leaderboard](https://huggingface.co/JosephusCheung/tmp/resolve/main/leaderboard.png)