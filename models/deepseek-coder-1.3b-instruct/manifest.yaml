id: deepseek-coder-1.3b-instruct
parent_id: deepseek-ai/deepseek-coder-1.3b-instruct
name: Deepseek Coder 1.3B Instruct
description: ""
architecture: llama
licence: other
object: model
owned_by: DeepSeek
pipeline: ""
languages: []
tags:
- transformers
- gguf
- deepseek
- base_model:deepseek-ai/deepseek-coder-1.3b-instruct
- license:other
- has_space
- region:us
config:
  vocab_size: 32256
  context_size: 16384
  embedding_size: 2048
  attention_head_size: 16
  key_value_head_size: 16
  intermediate_size: 5504
  hidden_layer_size: 24
variants:
  Q2_K:
    dtype: Q2_K
    backend: llama-backend
    backend_arguments:
    - --model
    - models/deepseek-coder-1.3b-instruct/Q2_K/Q2_K.gguf
    - --ctx-size
    - "16384"
    - --n-gpu-layers
    - "27"
    artifacts:
    - id: 80f2d3d91780255a4c34ed8dbcf8129cc5032ba2
      name: Q2_K.gguf
      uri: https://huggingface.co/TheBloke/deepseek-coder-1.3b-instruct-GGUF/resolve/main/deepseek-coder-1.3b-instruct.Q2_K.gguf
      size: 631705632
  Q3_K_L:
    dtype: Q3_K_L
    backend: llama-backend
    backend_arguments:
    - --model
    - models/deepseek-coder-1.3b-instruct/Q3_K_L/Q3_K_L.gguf
    - --ctx-size
    - "16384"
    - --n-gpu-layers
    - "27"
    artifacts:
    - id: 32c6906c59a387ecf5128d316b2d990779e1afee
      name: Q3_K_L.gguf
      uri: https://huggingface.co/TheBloke/deepseek-coder-1.3b-instruct-GGUF/resolve/main/deepseek-coder-1.3b-instruct.Q3_K_L.gguf
      size: 744583200
  Q3_K_M:
    dtype: Q3_K_M
    backend: llama-backend
    backend_arguments:
    - --model
    - models/deepseek-coder-1.3b-instruct/Q3_K_M/Q3_K_M.gguf
    - --ctx-size
    - "16384"
    - --n-gpu-layers
    - "27"
    artifacts:
    - id: 7a984efff8e491493ea876f4923430811041647a
      name: Q3_K_M.gguf
      uri: https://huggingface.co/TheBloke/deepseek-coder-1.3b-instruct-GGUF/resolve/main/deepseek-coder-1.3b-instruct.Q3_K_M.gguf
      size: 704966688
  Q3_K_S:
    dtype: Q3_K_S
    backend: llama-backend
    backend_arguments:
    - --model
    - models/deepseek-coder-1.3b-instruct/Q3_K_S/Q3_K_S.gguf
    - --ctx-size
    - "16384"
    - --n-gpu-layers
    - "27"
    artifacts:
    - id: a09b82a239aa725ba8134c58a6d42a1f9e45376e
      name: Q3_K_S.gguf
      uri: https://huggingface.co/TheBloke/deepseek-coder-1.3b-instruct-GGUF/resolve/main/deepseek-coder-1.3b-instruct.Q3_K_S.gguf
      size: 658862112
  Q4_0:
    dtype: Q4_0
    backend: llama-backend
    backend_arguments:
    - --model
    - models/deepseek-coder-1.3b-instruct/Q4_0/Q4_0.gguf
    - --ctx-size
    - "16384"
    - --n-gpu-layers
    - "27"
    artifacts:
    - id: 16427753a05d0441891a06258aaf37606431e3f1
      name: Q4_0.gguf
      uri: https://huggingface.co/TheBloke/deepseek-coder-1.3b-instruct-GGUF/resolve/main/deepseek-coder-1.3b-instruct.Q4_0.gguf
      size: 776065056
  Q4_K_M:
    dtype: Q4_K_M
    backend: llama-backend
    backend_arguments:
    - --model
    - models/deepseek-coder-1.3b-instruct/Q4_K_M/Q4_K_M.gguf
    - --ctx-size
    - "16384"
    - --n-gpu-layers
    - "27"
    artifacts:
    - id: e80e98ddd655bd73e9c16e3e6f3112229da02a18
      name: Q4_K_M.gguf
      uri: https://huggingface.co/TheBloke/deepseek-coder-1.3b-instruct-GGUF/resolve/main/deepseek-coder-1.3b-instruct.Q4_K_M.gguf
      size: 873582624
  Q4_K_S:
    dtype: Q4_K_S
    backend: llama-backend
    backend_arguments:
    - --model
    - models/deepseek-coder-1.3b-instruct/Q4_K_S/Q4_K_S.gguf
    - --ctx-size
    - "16384"
    - --n-gpu-layers
    - "27"
    artifacts:
    - id: 18dbdde10cdc1b3bc7c66a8ae54f56f172ee6ee4
      name: Q4_K_S.gguf
      uri: https://huggingface.co/TheBloke/deepseek-coder-1.3b-instruct-GGUF/resolve/main/deepseek-coder-1.3b-instruct.Q4_K_S.gguf
      size: 814796832
  Q5_0:
    dtype: Q5_0
    backend: llama-backend
    backend_arguments:
    - --model
    - models/deepseek-coder-1.3b-instruct/Q5_0/Q5_0.gguf
    - --ctx-size
    - "16384"
    - --n-gpu-layers
    - "27"
    artifacts:
    - id: 6aac437c57e3901f2ef1e56c33ae67b039d3df09
      name: Q5_0.gguf
      uri: https://huggingface.co/TheBloke/deepseek-coder-1.3b-instruct-GGUF/resolve/main/deepseek-coder-1.3b-instruct.Q5_0.gguf
      size: 936103968
  Q5_K_M:
    dtype: Q5_K_M
    backend: llama-backend
    backend_arguments:
    - --model
    - models/deepseek-coder-1.3b-instruct/Q5_K_M/Q5_K_M.gguf
    - --ctx-size
    - "16384"
    - --n-gpu-layers
    - "27"
    artifacts:
    - id: 8c4a6b1bb0e3b0f18c5e3a8a564dc7bb7c622757
      name: Q5_K_M.gguf
      uri: https://huggingface.co/TheBloke/deepseek-coder-1.3b-instruct-GGUF/resolve/main/deepseek-coder-1.3b-instruct.Q5_K_M.gguf
      size: 1001967648
  Q5_K_S:
    dtype: Q5_K_S
    backend: llama-backend
    backend_arguments:
    - --model
    - models/deepseek-coder-1.3b-instruct/Q5_K_S/Q5_K_S.gguf
    - --ctx-size
    - "16384"
    - --n-gpu-layers
    - "27"
    artifacts:
    - id: a9df9121a2b4b8608ca03ec8a306f55c91912a76
      name: Q5_K_S.gguf
      uri: https://huggingface.co/TheBloke/deepseek-coder-1.3b-instruct-GGUF/resolve/main/deepseek-coder-1.3b-instruct.Q5_K_S.gguf
      size: 953012256
  Q6_K:
    dtype: Q6_K
    backend: llama-backend
    backend_arguments:
    - --model
    - models/deepseek-coder-1.3b-instruct/Q6_K/Q6_K.gguf
    - --ctx-size
    - "16384"
    - --n-gpu-layers
    - "27"
    artifacts:
    - id: 1ae933d464e0ff7d76c1d336d768fd818e806811
      name: Q6_K.gguf
      uri: https://huggingface.co/TheBloke/deepseek-coder-1.3b-instruct-GGUF/resolve/main/deepseek-coder-1.3b-instruct.Q6_K.gguf
      size: 1171664928
  Q8_0:
    dtype: Q8_0
    backend: llama-backend
    backend_arguments:
    - --model
    - models/deepseek-coder-1.3b-instruct/Q8_0/Q8_0.gguf
    - --ctx-size
    - "16384"
    - --n-gpu-layers
    - "27"
    artifacts:
    - id: 669018b83039bdc64858c0237bbf79cf2252df7e
      name: Q8_0.gguf
      uri: https://huggingface.co/TheBloke/deepseek-coder-1.3b-instruct-GGUF/resolve/main/deepseek-coder-1.3b-instruct.Q8_0.gguf
      size: 1432219680
inference:
  chat:
    options:
      frequency_penalty: 0.0
      max_tokens: 16384
      "n": 1
      presence_penalty: 0.0
      stop:
      - </s>
      - "User:"
      - "Co:Here:"
      stream: true
      temperature: 0.8
      top_k: 40
      top_p: 0.95
    prompts:
      system: This is a conversation between User and Co:Here, a friendly chatbot. Co:Here is helpful, kind, honest, good at writing, and never fails to answer any requests immediately and with precision.
      template: "You are an AI programming assistant, utilizing the Deepseek Coder model, developed by Deepseek Company, and you only answer questions related to computer science. For politically sensitive questions, security and privacy issues, and other non-computer science questions, you will refuse to answer.\n### Instruction:\n{prompt}\n### Response:\n"
