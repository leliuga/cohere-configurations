id: Pygmalion-2-13B/Q4_0
parent_id: PygmalionAI/pygmalion-2-13b
name: Pygmalion 2 13B
description: ""
architecture: llama
licence: llama2
object: model
owned_by: PygmalionAI
artifact: https://huggingface.co/TheBloke/Pygmalion-2-13B-GGUF/resolve/main/pygmalion-2-13b.Q4_0.gguf
pipeline: text-generation
languages: []
tags:
- transformers
- gguf
- llama
- text generation
- instruct
- text-generation
- en
- dataset:PygmalionAI/PIPPA
- dataset:Open-Orca/OpenOrca
- dataset:Norquinal/claude_multiround_chat_30k
- dataset:jondurbin/airoboros-gpt4-1.4.1
- dataset:databricks/databricks-dolly-15k
- base_model:PygmalionAI/pygmalion-2-13b
- license:llama2
- text-generation-inference
- region:us
dtype: Q4_0
file_size: 7365834624
params_size: ""
vocab_size: 32000
context_size: 4096
embedding_size: 5120
pretrained: false
finetuned: false
quantized: true
backend: llama-backend
chat_options:
  cache_prompt: true
  frequency_penalty: 0.0
  grammar: ""
  ignore_eos: false
  mirostat: 0
  mirostat_eta: 0.1
  mirostat_tau: 5.0
  n_keep: -1
  n_predict: -1
  n_probs: 0
  penalize_nl: true
  presence_penalty: 0.0
  repeat_last_n: 64
  repeat_penalty: 1.1
  seed: -1
  temperature: 0.8
  tfs_z: 1.0
  top_k: 40
  top_p: 0.95
  typical_p: 1.0
prompt:
  system: This is a conversation between User and Co:Here, a friendly chatbot. Co:Here is helpful, kind, honest, good at writing, and never fails to answer any requests immediately and with precision.
  template: "The model has been trained on prompts using three different roles, which are denoted by the following tokens: `<|system|>`, `<|user|>` and `<|model|>`.\n\nThe `<|system|>` prompt can be used to inject out-of-channel information behind the scenes, while the `<|user|>` prompt should be used to indicate user input.\nThe `<|model|>` token should then be used to indicate that the model should generate a response. These tokens can happen multiple times and be chained up to form a conversation history.\n\nThe system prompt has been designed to allow the model to \"enter\" various modes and dictate the reply length. Here's an example:\n\n```\n<|system|>Enter RP mode. Pretend to be {{char}} whose persona follows:\n{{persona}}\n\nYou shall reply to the user while staying in character, and generate long responses.\n```\n"
