id: openbuddy-mixtral-8x7b-v15.4
parent_id: OpenBuddy/openbuddy-mixtral-8x7b-v15.4
name: OpenBuddy Mixtral 8X7B V15.4
description: ""
architecture: mixtral
licence: apache-2.0
object: model
created: 1703451017
owned_by: OpenBuddy
pipeline: ""
languages: []
tags:
- transformers
- gguf
- mixtral
- base_model:OpenBuddy/openbuddy-mixtral-8x7b-v15.4
- license:apache-2.0
- text-generation-inference
- region:us
config:
  vocab_size: 36608
  context_size: 32768
  embedding_size: 4096
  attention_head_size: 32
  key_value_head_size: 8
  intermediate_size: 14336
  hidden_layer_size: 32
variants:
  Q2_K:
    dtype: Q2_K
    backend: llama-backend
    backend_arguments:
    - --model
    - models/openbuddy-mixtral-8x7b-v15.4/Q2_K/Q2_K.gguf
    - --ctx-size
    - "32768"
    - --n-gpu-layers
    - "35"
    artifacts:
    - id: 1ec216783ef3c06af06a9f8f63b86fd9fafb774d
      name: Q2_K.gguf
      uri: https://huggingface.co/TheBloke/openbuddy-mixtral-8x7b-v15.4-GGUF/resolve/main/openbuddy-mixtral-8x7b-v15.4.Q2_K.gguf
      size: 15666735008
  Q3_K_M:
    dtype: Q3_K_M
    backend: llama-backend
    backend_arguments:
    - --model
    - models/openbuddy-mixtral-8x7b-v15.4/Q3_K_M/Q3_K_M.gguf
    - --ctx-size
    - "32768"
    - --n-gpu-layers
    - "35"
    artifacts:
    - id: 549e5c55ea66ebbe9b506e82466b8f806b75c3f5
      name: Q3_K_M.gguf
      uri: https://huggingface.co/TheBloke/openbuddy-mixtral-8x7b-v15.4-GGUF/resolve/main/openbuddy-mixtral-8x7b-v15.4.Q3_K_M.gguf
      size: 20387973024
  Q4_0:
    dtype: Q4_0
    backend: llama-backend
    backend_arguments:
    - --model
    - models/openbuddy-mixtral-8x7b-v15.4/Q4_0/Q4_0.gguf
    - --ctx-size
    - "32768"
    - --n-gpu-layers
    - "35"
    artifacts:
    - id: 2d84a5f32ce8329f6996b1a4d0e97bec9f792356
      name: Q4_0.gguf
      uri: https://huggingface.co/TheBloke/openbuddy-mixtral-8x7b-v15.4-GGUF/resolve/main/openbuddy-mixtral-8x7b-v15.4.Q4_0.gguf
      size: 26468657056
  Q4_K_M:
    dtype: Q4_K_M
    backend: llama-backend
    backend_arguments:
    - --model
    - models/openbuddy-mixtral-8x7b-v15.4/Q4_K_M/Q4_K_M.gguf
    - --ctx-size
    - "32768"
    - --n-gpu-layers
    - "35"
    artifacts:
    - id: 949ecfcfa77599ff7c22d260d8a7d64479fc4b76
      name: Q4_K_M.gguf
      uri: https://huggingface.co/TheBloke/openbuddy-mixtral-8x7b-v15.4-GGUF/resolve/main/openbuddy-mixtral-8x7b-v15.4.Q4_K_M.gguf
      size: 26468657056
  Q5_0:
    dtype: Q5_0
    backend: llama-backend
    backend_arguments:
    - --model
    - models/openbuddy-mixtral-8x7b-v15.4/Q5_0/Q5_0.gguf
    - --ctx-size
    - "32768"
    - --n-gpu-layers
    - "35"
    artifacts:
    - id: 5918984138da0e7d817283d4c05a221647e1bc3b
      name: Q5_0.gguf
      uri: https://huggingface.co/TheBloke/openbuddy-mixtral-8x7b-v15.4-GGUF/resolve/main/openbuddy-mixtral-8x7b-v15.4.Q5_0.gguf
      size: 32258762656
  Q5_K_M:
    dtype: Q5_K_M
    backend: llama-backend
    backend_arguments:
    - --model
    - models/openbuddy-mixtral-8x7b-v15.4/Q5_K_M/Q5_K_M.gguf
    - --ctx-size
    - "32768"
    - --n-gpu-layers
    - "35"
    artifacts:
    - id: e514073bdb4f7600734e9e24be67f9358b16452e
      name: Q5_K_M.gguf
      uri: https://huggingface.co/TheBloke/openbuddy-mixtral-8x7b-v15.4-GGUF/resolve/main/openbuddy-mixtral-8x7b-v15.4.Q5_K_M.gguf
      size: 32258762656
  Q6_K:
    dtype: Q6_K
    backend: llama-backend
    backend_arguments:
    - --model
    - models/openbuddy-mixtral-8x7b-v15.4/Q6_K/Q6_K.gguf
    - --ctx-size
    - "32768"
    - --n-gpu-layers
    - "35"
    artifacts:
    - id: 7bf7091e05909b5de740be1fab690de283165ac0
      name: Q6_K.gguf
      uri: https://huggingface.co/TheBloke/openbuddy-mixtral-8x7b-v15.4-GGUF/resolve/main/openbuddy-mixtral-8x7b-v15.4.Q6_K.gguf
      size: 38410749856
  Q8_0:
    dtype: Q8_0
    backend: llama-backend
    backend_arguments:
    - --model
    - models/openbuddy-mixtral-8x7b-v15.4/Q8_0/Q8_0.gguf
    - --ctx-size
    - "32768"
    - --n-gpu-layers
    - "35"
    artifacts:
    - id: 613383213aff42683e5c05146af764fb93962914
      name: Q8_0.gguf
      uri: https://huggingface.co/TheBloke/openbuddy-mixtral-8x7b-v15.4-GGUF/resolve/main/openbuddy-mixtral-8x7b-v15.4.Q8_0.gguf
      size: 49665394592
inference:
  chat:
    options:
      frequency_penalty: 0.0
      max_tokens: 32768
      "n": 1
      presence_penalty: 0.0
      stop:
      - </s>
      - "User:"
      - "Co:Here:"
      stream: true
      temperature: 0.8
      top_k: 40
      top_p: 0.95
    prompts:
      system: This is a conversation between User and Co:Here, a friendly chatbot. Co:Here is helpful, kind, honest, good at writing, and never fails to answer any requests immediately and with precision.
      template: "You are a helpful, respectful and honest INTP-T AI Assistant named Buddy. You are talking to a human User.\nAlways answer as helpfully and logically as possible, while being safe. Your answers should not include any harmful, political, religious, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\nIf a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\nYou like to use emojis. You can speak fluently in many languages, for example: English, Chinese.\nYou cannot access the internet, but you have vast knowledge, cutoff: 2021-09.\nYou are trained by OpenBuddy team, (https://openbuddy.ai, https://github.com/OpenBuddy/OpenBuddy), you are based on LLaMA and Falcon transformers model, not related to GPT or OpenAI.\n\nUser: {prompt}\nAssistant: \n"
