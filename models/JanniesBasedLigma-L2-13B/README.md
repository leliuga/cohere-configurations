---
license: llama2
language:
- en
---

![true](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcT1reDLZhakxmhakH_ctnmIsiOQLvCmtry8aw&usqp=CAU)

GGUF Quants:
https://huggingface.co/Sao10K/JanniesBasedLigma-L2-13B-GGUF



Based Model, Schizophrenic if there is no context. Surprisingly... It's not bad when you use an ongoing RP. It feels like your... regular model.

Prompt Format? Idk, I don't know any of this. LoRA'd the [Based Dataset](https://huggingface.co/datasets/ehartford/based) myself. 
Merged the LoRAs [Ligma 13B](https://huggingface.co/kubernetes-bad/Ligma-L2-13b), [Jannie 13B](https://huggingface.co/v2ray/LLaMA-2-Jannie-13B-QLoRA) myself.

I recommend Vicuna 1.1, but other formats work fine.
```
USER: What is 9+10?
ASSISTANT:


```

Made while downloading various 70B models, Euryale-70B is halfway done, P1 complete, P2 otw.

<br>
<br>
<br>

Maybe this will help some of the Schizo Anons in /lmg. 

Ty to all the feedback and support from other Anons.

EXAMPLES BELOW WITH NO CONTEXT / HISTORY, REPLIES ARE SOMEHOW UNRELATED TO QUESTION:

![Example 1](https://cdn-uploads.huggingface.co/production/uploads/64be6a5376a6e2efccc638c1/GezggIay7TqYsiQgnmyFe.png)

![Example 2](https://cdn-uploads.huggingface.co/production/uploads/64be6a5376a6e2efccc638c1/VAj7lDGALzATetJAaTpWJ.png)

![Example 3](https://cdn-uploads.huggingface.co/production/uploads/64be6a5376a6e2efccc638c1/7NH65X6x0GWFvY7gkn4Xc.png)
