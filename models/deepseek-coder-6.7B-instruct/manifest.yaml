id: deepseek-coder-6.7B-instruct
parent_id: deepseek-ai/deepseek-coder-6.7b-instruct
name: Deepseek Coder 6.7B Instruct
description: ""
architecture: llama
licence: other
object: model
created: 1699191363
owned_by: DeepSeek
pipeline: ""
languages: []
tags:
- transformers
- gguf
- deepseek
- base_model:deepseek-ai/deepseek-coder-6.7b-instruct
- license:other
- has_space
- region:us
config:
  vocab_size: 32256
  context_size: 16384
  embedding_size: 4096
  attention_head_size: 32
  key_value_head_size: 32
  intermediate_size: 11008
  hidden_layer_size: 32
variants:
  Q2_K:
    dtype: Q2_K
    backend: llama-backend
    backend_arguments:
    - --model
    - models/deepseek-coder-6.7B-instruct/Q2_K/Q2_K.gguf
    - --ctx-size
    - "16384"
    - --n-gpu-layers
    - "35"
    artifacts:
    - id: 2af648acc9befd72cf272effd58869cbe74703c2
      name: Q2_K.gguf
      uri: https://huggingface.co/TheBloke/deepseek-coder-6.7B-instruct-GGUF/resolve/main/deepseek-coder-6.7b-instruct.Q2_K.gguf
      size: 2827706592
  Q3_K_L:
    dtype: Q3_K_L
    backend: llama-backend
    backend_arguments:
    - --model
    - models/deepseek-coder-6.7B-instruct/Q3_K_L/Q3_K_L.gguf
    - --ctx-size
    - "16384"
    - --n-gpu-layers
    - "35"
    artifacts:
    - id: f2f036785fcabada6643d6c05bc06771915558f0
      name: Q3_K_L.gguf
      uri: https://huggingface.co/TheBloke/deepseek-coder-6.7B-instruct-GGUF/resolve/main/deepseek-coder-6.7b-instruct.Q3_K_L.gguf
      size: 3598983392
  Q3_K_M:
    dtype: Q3_K_M
    backend: llama-backend
    backend_arguments:
    - --model
    - models/deepseek-coder-6.7B-instruct/Q3_K_M/Q3_K_M.gguf
    - --ctx-size
    - "16384"
    - --n-gpu-layers
    - "35"
    artifacts:
    - id: 6a293d175d58d4aa585db48b10b78bada253a01a
      name: Q3_K_M.gguf
      uri: https://huggingface.co/TheBloke/deepseek-coder-6.7B-instruct-GGUF/resolve/main/deepseek-coder-6.7b-instruct.Q3_K_M.gguf
      size: 3299877088
  Q3_K_S:
    dtype: Q3_K_S
    backend: llama-backend
    backend_arguments:
    - --model
    - models/deepseek-coder-6.7B-instruct/Q3_K_S/Q3_K_S.gguf
    - --ctx-size
    - "16384"
    - --n-gpu-layers
    - "35"
    artifacts:
    - id: 29df8c7b2952654355252400db21bf00f0f70851
      name: Q3_K_S.gguf
      uri: https://huggingface.co/TheBloke/deepseek-coder-6.7B-instruct-GGUF/resolve/main/deepseek-coder-6.7b-instruct.Q3_K_S.gguf
      size: 2950176992
  Q4_0:
    dtype: Q4_0
    backend: llama-backend
    backend_arguments:
    - --model
    - models/deepseek-coder-6.7B-instruct/Q4_0/Q4_0.gguf
    - --ctx-size
    - "16384"
    - --n-gpu-layers
    - "35"
    artifacts:
    - id: 992c0acbb576cd5284a403e3d797deb6957511d5
      name: Q4_0.gguf
      uri: https://huggingface.co/TheBloke/deepseek-coder-6.7B-instruct-GGUF/resolve/main/deepseek-coder-6.7b-instruct.Q4_0.gguf
      size: 3827818720
  Q4_K_M:
    dtype: Q4_K_M
    backend: llama-backend
    backend_arguments:
    - --model
    - models/deepseek-coder-6.7B-instruct/Q4_K_M/Q4_K_M.gguf
    - --ctx-size
    - "16384"
    - --n-gpu-layers
    - "35"
    artifacts:
    - id: 0a10b6cf236027c327c0a6aac9b9a5d9f08bc314
      name: Q4_K_M.gguf
      uri: https://huggingface.co/TheBloke/deepseek-coder-6.7B-instruct-GGUF/resolve/main/deepseek-coder-6.7b-instruct.Q4_K_M.gguf
      size: 4083015904
  Q4_K_S:
    dtype: Q4_K_S
    backend: llama-backend
    backend_arguments:
    - --model
    - models/deepseek-coder-6.7B-instruct/Q4_K_S/Q4_K_S.gguf
    - --ctx-size
    - "16384"
    - --n-gpu-layers
    - "35"
    artifacts:
    - id: 0b1f80926a6510c39d09d17525fceb489dd90683
      name: Q4_K_S.gguf
      uri: https://huggingface.co/TheBloke/deepseek-coder-6.7B-instruct-GGUF/resolve/main/deepseek-coder-6.7b-instruct.Q4_K_S.gguf
      size: 3858751712
  Q5_0:
    dtype: Q5_0
    backend: llama-backend
    backend_arguments:
    - --model
    - models/deepseek-coder-6.7B-instruct/Q5_0/Q5_0.gguf
    - --ctx-size
    - "16384"
    - --n-gpu-layers
    - "35"
    artifacts:
    - id: 9fafd1203fad5ea6902454f2393e5809ed2ee41e
      name: Q5_0.gguf
      uri: https://huggingface.co/TheBloke/deepseek-coder-6.7B-instruct-GGUF/resolve/main/deepseek-coder-6.7b-instruct.Q5_0.gguf
      size: 4653834464
  Q5_K_M:
    dtype: Q5_K_M
    backend: llama-backend
    backend_arguments:
    - --model
    - models/deepseek-coder-6.7B-instruct/Q5_K_M/Q5_K_M.gguf
    - --ctx-size
    - "16384"
    - --n-gpu-layers
    - "35"
    artifacts:
    - id: 3709e70086ef2ad946f94c0179cef6fadb0a9e1b
      name: Q5_K_M.gguf
      uri: https://huggingface.co/TheBloke/deepseek-coder-6.7B-instruct-GGUF/resolve/main/deepseek-coder-6.7b-instruct.Q5_K_M.gguf
      size: 4785299680
  Q5_K_S:
    dtype: Q5_K_S
    backend: llama-backend
    backend_arguments:
    - --model
    - models/deepseek-coder-6.7B-instruct/Q5_K_S/Q5_K_S.gguf
    - --ctx-size
    - "16384"
    - --n-gpu-layers
    - "35"
    artifacts:
    - id: 459af615359db7ff9e1fbc54033732c22fba5636
      name: Q5_K_S.gguf
      uri: https://huggingface.co/TheBloke/deepseek-coder-6.7B-instruct-GGUF/resolve/main/deepseek-coder-6.7b-instruct.Q5_K_S.gguf
      size: 4653834464
  Q6_K:
    dtype: Q6_K
    backend: llama-backend
    backend_arguments:
    - --model
    - models/deepseek-coder-6.7B-instruct/Q6_K/Q6_K.gguf
    - --ctx-size
    - "16384"
    - --n-gpu-layers
    - "35"
    artifacts:
    - id: 4d2da6eb72fc1727feb1cad9987afe9d97569a24
      name: Q6_K.gguf
      uri: https://huggingface.co/TheBloke/deepseek-coder-6.7B-instruct-GGUF/resolve/main/deepseek-coder-6.7b-instruct.Q6_K.gguf
      size: 5531476192
  Q8_0:
    dtype: Q8_0
    backend: llama-backend
    backend_arguments:
    - --model
    - models/deepseek-coder-6.7B-instruct/Q8_0/Q8_0.gguf
    - --ctx-size
    - "16384"
    - --n-gpu-layers
    - "35"
    artifacts:
    - id: bed40e897691a2400111a914553e68732f269b82
      name: Q8_0.gguf
      uri: https://huggingface.co/TheBloke/deepseek-coder-6.7B-instruct-GGUF/resolve/main/deepseek-coder-6.7b-instruct.Q8_0.gguf
      size: 7163879648
inference:
  chat:
    options:
      frequency_penalty: 0.0
      max_tokens: 16384
      "n": 1
      presence_penalty: 0.0
      stop:
      - </s>
      - "User:"
      - "Co:Here:"
      stream: true
      temperature: 0.8
      top_k: 40
      top_p: 0.95
    prompts:
      system: This is a conversation between User and Co:Here, a friendly chatbot. Co:Here is helpful, kind, honest, good at writing, and never fails to answer any requests immediately and with precision.
      template: "You are an AI programming assistant, utilizing the Deepseek Coder model, developed by Deepseek Company, and you only answer questions related to computer science. For politically sensitive questions, security and privacy issues, and other non-computer science questions, you will refuse to answer.\n### Instruction:\n{prompt}\n### Response:\n"
