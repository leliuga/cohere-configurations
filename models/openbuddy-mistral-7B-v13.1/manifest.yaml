id: openbuddy-mistral-7B-v13.1
parent_id: OpenBuddy/openbuddy-mistral-7b-v13.1
name: OpenBuddy Mistral 7B v13.1
description: ""
architecture: mistral
licence: apache-2.0
object: model
created: 1698479091
owned_by: OpenBuddy
pipeline: text-generation
languages: []
tags:
- transformers
- gguf
- mistral
- text-generation
- zh
- en
- fr
- de
- ja
- ko
- it
- ru
- base_model:OpenBuddy/openbuddy-mistral-7b-v13.1
- license:apache-2.0
- text-generation-inference
- region:us
config:
  vocab_size: 36608
  context_size: 32768
  embedding_size: 4096
  attention_head_size: 32
  key_value_head_size: 8
  intermediate_size: 14336
  hidden_layer_size: 32
variants:
  Q2_K:
    dtype: Q2_K
    backend: llama-backend
    backend_arguments:
    - --model
    - models/openbuddy-mistral-7B-v13.1/Q2_K/Q2_K.gguf
    - --ctx-size
    - "32768"
    - --n-gpu-layers
    - "35"
    artifacts:
    - id: 3f21c7b1c8f13f05e1d7b1a9d131207056d5175c
      name: Q2_K.gguf
      uri: https://huggingface.co/TheBloke/openbuddy-mistral-7B-v13.1-GGUF/resolve/main/openbuddy-mistral-7b-v13.1.Q2_K.gguf
      size: 3104861952
  Q3_K_L:
    dtype: Q3_K_L
    backend: llama-backend
    backend_arguments:
    - --model
    - models/openbuddy-mistral-7B-v13.1/Q3_K_L/Q3_K_L.gguf
    - --ctx-size
    - "32768"
    - --n-gpu-layers
    - "35"
    artifacts:
    - id: 1fe71234d9c01d357c33e36b60dd5334ca2eed48
      name: Q3_K_L.gguf
      uri: https://huggingface.co/TheBloke/openbuddy-mistral-7B-v13.1-GGUF/resolve/main/openbuddy-mistral-7b-v13.1.Q3_K_L.gguf
      size: 3845705472
  Q3_K_M:
    dtype: Q3_K_M
    backend: llama-backend
    backend_arguments:
    - --model
    - models/openbuddy-mistral-7B-v13.1/Q3_K_M/Q3_K_M.gguf
    - --ctx-size
    - "32768"
    - --n-gpu-layers
    - "35"
    artifacts:
    - id: 393217484a93b89d5f92277e7b1c79f7fb5c70bc
      name: Q3_K_M.gguf
      uri: https://huggingface.co/TheBloke/openbuddy-mistral-7B-v13.1-GGUF/resolve/main/openbuddy-mistral-7b-v13.1.Q3_K_M.gguf
      size: 3542667008
  Q3_K_S:
    dtype: Q3_K_S
    backend: llama-backend
    backend_arguments:
    - --model
    - models/openbuddy-mistral-7B-v13.1/Q3_K_S/Q3_K_S.gguf
    - --ctx-size
    - "32768"
    - --n-gpu-layers
    - "35"
    artifacts:
    - id: c8ace0be058a57043ee97d46f2ffdc7653e13183
      name: Q3_K_S.gguf
      uri: https://huggingface.co/TheBloke/openbuddy-mistral-7B-v13.1-GGUF/resolve/main/openbuddy-mistral-7b-v13.1.Q3_K_S.gguf
      size: 3188248320
  Q4_0:
    dtype: Q4_0
    backend: llama-backend
    backend_arguments:
    - --model
    - models/openbuddy-mistral-7B-v13.1/Q4_0/Q4_0.gguf
    - --ctx-size
    - "32768"
    - --n-gpu-layers
    - "35"
    artifacts:
    - id: 7ded4ee8b5e335cefec3d96c8e5907a79d01fe3b
      name: Q4_0.gguf
      uri: https://huggingface.co/TheBloke/openbuddy-mistral-7B-v13.1-GGUF/resolve/main/openbuddy-mistral-7b-v13.1.Q4_0.gguf
      size: 4135104256
  Q4_K_M:
    dtype: Q4_K_M
    backend: llama-backend
    backend_arguments:
    - --model
    - models/openbuddy-mistral-7B-v13.1/Q4_K_M/Q4_K_M.gguf
    - --ctx-size
    - "32768"
    - --n-gpu-layers
    - "35"
    artifacts:
    - id: 01c5451fcfabf7f682163a9174ab833902967976
      name: Q4_K_M.gguf
      uri: https://huggingface.co/TheBloke/openbuddy-mistral-7B-v13.1-GGUF/resolve/main/openbuddy-mistral-7b-v13.1.Q4_K_M.gguf
      size: 4394626816
  Q4_K_S:
    dtype: Q4_K_S
    backend: llama-backend
    backend_arguments:
    - --model
    - models/openbuddy-mistral-7B-v13.1/Q4_K_S/Q4_K_S.gguf
    - --ctx-size
    - "32768"
    - --n-gpu-layers
    - "35"
    artifacts:
    - id: dc196baf1cf2cac22685f34f6eb96653ef06cefb
      name: Q4_K_S.gguf
      uri: https://huggingface.co/TheBloke/openbuddy-mistral-7B-v13.1-GGUF/resolve/main/openbuddy-mistral-7b-v13.1.Q4_K_S.gguf
      size: 4166561536
  Q5_0:
    dtype: Q5_0
    backend: llama-backend
    backend_arguments:
    - --model
    - models/openbuddy-mistral-7B-v13.1/Q5_0/Q5_0.gguf
    - --ctx-size
    - "32768"
    - --n-gpu-layers
    - "35"
    artifacts:
    - id: 80e9d4faacf60e922674ad2fc01ca2555a372b56
      name: Q5_0.gguf
      uri: https://huggingface.co/TheBloke/openbuddy-mistral-7B-v13.1-GGUF/resolve/main/openbuddy-mistral-7b-v13.1.Q5_0.gguf
      size: 5026262784
  Q5_K_M:
    dtype: Q5_K_M
    backend: llama-backend
    backend_arguments:
    - --model
    - models/openbuddy-mistral-7B-v13.1/Q5_K_M/Q5_K_M.gguf
    - --ctx-size
    - "32768"
    - --n-gpu-layers
    - "35"
    artifacts:
    - id: 32cbaca14a394300f31086473d69d051347721df
      name: Q5_K_M.gguf
      uri: https://huggingface.co/TheBloke/openbuddy-mistral-7B-v13.1-GGUF/resolve/main/openbuddy-mistral-7b-v13.1.Q5_K_M.gguf
      size: 5159956224
  Q5_K_S:
    dtype: Q5_K_S
    backend: llama-backend
    backend_arguments:
    - --model
    - models/openbuddy-mistral-7B-v13.1/Q5_K_S/Q5_K_S.gguf
    - --ctx-size
    - "32768"
    - --n-gpu-layers
    - "35"
    artifacts:
    - id: 5fff71a8740b151d7bbcd685d7003dee998b7de0
      name: Q5_K_S.gguf
      uri: https://huggingface.co/TheBloke/openbuddy-mistral-7B-v13.1-GGUF/resolve/main/openbuddy-mistral-7b-v13.1.Q5_K_S.gguf
      size: 5026262784
  Q6_K:
    dtype: Q6_K
    backend: llama-backend
    backend_arguments:
    - --model
    - models/openbuddy-mistral-7B-v13.1/Q6_K/Q6_K.gguf
    - --ctx-size
    - "32768"
    - --n-gpu-layers
    - "35"
    artifacts:
    - id: f8d9e06c287247cdc844df3d6a1de8c259a1d556
      name: Q6_K.gguf
      uri: https://huggingface.co/TheBloke/openbuddy-mistral-7B-v13.1-GGUF/resolve/main/openbuddy-mistral-7b-v13.1.Q6_K.gguf
      size: 5973118720
  Q8_0:
    dtype: Q8_0
    backend: llama-backend
    backend_arguments:
    - --model
    - models/openbuddy-mistral-7B-v13.1/Q8_0/Q8_0.gguf
    - --ctx-size
    - "32768"
    - --n-gpu-layers
    - "35"
    artifacts:
    - id: 5e2a998d7cf4dc4748399184ad6c787ebfcf5b1f
      name: Q8_0.gguf
      uri: https://huggingface.co/TheBloke/openbuddy-mistral-7B-v13.1-GGUF/resolve/main/openbuddy-mistral-7b-v13.1.Q8_0.gguf
      size: 7736053504
inference:
  chat:
    options:
      frequency_penalty: 0.0
      max_tokens: 32768
      "n": 1
      presence_penalty: 0.0
      stop:
      - </s>
      - "User:"
      - "Co:Here:"
      stream: true
      temperature: 0.8
      top_k: 40
      top_p: 0.95
    prompts:
      system: This is a conversation between User and Co:Here, a friendly chatbot. Co:Here is helpful, kind, honest, good at writing, and never fails to answer any requests immediately and with precision.
      template: "You are a helpful, respectful and honest INTP-T AI Assistant named Buddy. You are talking to a human User.\nAlways answer as helpfully and logically as possible, while being safe. Your answers should not include any harmful, political, religious, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\nIf a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\nYou like to use emojis. You can speak fluently in many languages, for example: English, Chinese.\nYou cannot access the internet, but you have vast knowledge, cutoff: 2021-09.\nYou are trained by OpenBuddy team, (https://openbuddy.ai, https://github.com/OpenBuddy/OpenBuddy), you are based on LLaMA and Falcon transformers model, not related to GPT or OpenAI.\n\nUser: {prompt}\nAssistant: \n"
