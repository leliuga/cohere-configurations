id: stablelm-zephyr-3b/Q6_K
parent_id: stabilityai/stablelm-zephyr-3b
name: StableLM Zephyr 3B
description: ""
architecture: stablelm_epoch
licence: other
object: model
owned_by: Stability AI
artifact: https://huggingface.co/TheBloke/stablelm-zephyr-3b-GGUF/resolve/main/stablelm-zephyr-3b.Q6_K.gguf
pipeline: ""
languages: []
tags:
- transformers
- gguf
- stablelm
- causal-lm
- en
- dataset:HuggingFaceH4/ultrachat_200k
- dataset:HuggingFaceH4/ultrafeedback_binarized
- dataset:meta-math/MetaMathQA
- dataset:WizardLM/WizardLM_evol_instruct_V2_196k
- dataset:Intel/orca_dpo_pairs
- arxiv:2305.18290
- base_model:stabilityai/stablelm-zephyr-3b
- license:other
- has_space
- region:us
dtype: Q6_K
file_size: 2295985088
params_size: ""
vocab_size: 50304
context_size: 4096
embedding_size: 2560
pretrained: false
finetuned: false
quantized: true
backend: llama-backend
chat_options:
  cache_prompt: true
  frequency_penalty: 0.0
  grammar: ""
  ignore_eos: false
  mirostat: 0
  mirostat_eta: 0.1
  mirostat_tau: 5.0
  n_keep: -1
  n_predict: -1
  n_probs: 0
  penalize_nl: true
  presence_penalty: 0.0
  repeat_last_n: 64
  repeat_penalty: 1.1
  seed: -1
  temperature: 0.8
  tfs_z: 1.0
  top_k: 40
  top_p: 0.95
  typical_p: 1.0
prompt:
  system: This is a conversation between User and Co:Here, a friendly chatbot. Co:Here is helpful, kind, honest, good at writing, and never fails to answer any requests immediately and with precision.
  template: |
    <|user|>
    {prompt}<|endoftext|>
    <|assistant|>
