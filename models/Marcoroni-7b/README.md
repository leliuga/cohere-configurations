---
license: cc-by-nc-4.0
datasets:
- Open-Orca/OpenOrca
language:
- en
pipeline_tag: text-generation
---
# Marcoroni-7B

# Model Details
* **Trained by**: trained by AIDC AI-Business.
* **Model type:**  **Marcoroni-7B** is an auto-regressive language model based on the Llama 2 transformer architecture.
* **Language(s)**: English
* **License for Marcoroni-7B base weights**: Non-Commercial Creative Commons license ([CC BY-NC-4.0](https://creativecommons.org/licenses/by-nc/4.0/))


# Prompting

## Prompt Template for alpaca style

```
### Instruction:

<prompt> (without the <>)

### Response:
```


# Evulation Results ([Open LLM Leaderboard](https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard))

| Metric                | Value |
|-----------------------|-------|
| Avg.                  |   60.1   |
| ARC (25-shot)         |   58.11   |
| HellaSwag (10-shot)   |   80.08   |
| MMLU (5-shot)         |   51.36   |
| TruthfulQA (0-shot)   |   50.85   |
