id: ShiningValiant-1.2/Q3_K_L
parent_id: ValiantLabs/ShiningValiant
name: ShiningValiant 1.2
description: ""
architecture: llama
licence: llama2
object: model
owned_by: Valiant Labs
artifact: https://huggingface.co/TheBloke/ShiningValiant-1.2-GGUF/resolve/main/shiningvaliant-1.2.Q3_K_L.gguf
pipeline: text-generation
languages: []
tags:
- transformers
- gguf
- llama
- shining-valiant
- valiant
- valiant-labs
- llama-2
- llama-2-chat
- 70b
- text-generation
- en
- base_model:ValiantLabs/ShiningValiant
- license:llama2
- text-generation-inference
- region:us
dtype: Q3_K_L
file_size: 36147835904
params_size: ""
vocab_size: 32000
context_size: 4096
embedding_size: 8192
pretrained: false
finetuned: false
quantized: true
backend: llama-backend
chat_options:
  cache_prompt: true
  frequency_penalty: 0.0
  grammar: ""
  ignore_eos: false
  mirostat: 0
  mirostat_eta: 0.1
  mirostat_tau: 5.0
  n_keep: -1
  n_predict: -1
  n_probs: 0
  penalize_nl: true
  presence_penalty: 0.0
  repeat_last_n: 64
  repeat_penalty: 1.1
  seed: -1
  temperature: 0.8
  tfs_z: 1.0
  top_k: 40
  top_p: 0.95
  typical_p: 1.0
prompt:
  system: This is a conversation between User and Co:Here, a friendly chatbot. Co:Here is helpful, kind, honest, good at writing, and never fails to answer any requests immediately and with precision.
  template: "[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature. If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\n<</SYS>>\n{prompt}[/INST]\n"
