id: Llama2-22B-Daydreamer-v3
parent_id: nkpz/llama2-22b-daydreamer-v3
name: Llama2 22B Daydreamer2 v3
description: ""
architecture: llama
licence: other
object: model
owned_by: Nick Perez
pipeline: ""
languages: []
tags:
- transformers
- gguf
- llama
- base_model:nkpz/llama2-22b-daydreamer-v3
- license:other
- text-generation-inference
- region:us
config:
  vocab_size: 32000
  context_size: 4098
  embedding_size: 6656
  attention_head_size: 52
  key_value_head_size: 52
  intermediate_size: 17920
  hidden_layer_size: 40
  tokens:
    bos:
      index: 1
      value: <s>
    eos:
      index: 2
      value: </s>
    lf:
      index: 13
      value: <0x0A>
    unk:
      index: 0
      value: <unk>
variants:
  Q2_K:
    dtype: Q2_K
    backend: llama-backend
    backend_arguments:
    - --model
    - models/Llama2-22B-Daydreamer-v3/Q2_K.gguf
    - --ctx-size
    - "4098"
    - --batch-size
    - "4096"
    - --n-gpu-layers
    - "43"
    - --parallel
    - "4"
    - --no-mmap
    - "false"
    - --mlock
    - "true"
    - --numa
    - "true"
    - --cont-batching
    - "true"
    - --embedding
    - "false"
    artifacts:
    - id: 493321ae447c7742dc6f535278577276af357937
      name: Q2_K.gguf
      uri: https://huggingface.co/TheBloke/Llama2-22B-Daydreamer-v3-GGUF/resolve/main/llama2-22b-daydreamer-v3.Q2_K.gguf
      size: 9083483040
  Q3_K_L:
    dtype: Q3_K_L
    backend: llama-backend
    backend_arguments:
    - --model
    - models/Llama2-22B-Daydreamer-v3/Q3_K_L.gguf
    - --ctx-size
    - "4098"
    - --batch-size
    - "4096"
    - --n-gpu-layers
    - "43"
    - --parallel
    - "4"
    - --no-mmap
    - "false"
    - --mlock
    - "true"
    - --numa
    - "true"
    - --cont-batching
    - "true"
    - --embedding
    - "false"
    artifacts:
    - id: 817a075ca699a3a209386ec5b4e7ea128b6ac741
      name: Q3_K_L.gguf
      uri: https://huggingface.co/TheBloke/Llama2-22B-Daydreamer-v3-GGUF/resolve/main/llama2-22b-daydreamer-v3.Q3_K_L.gguf
      size: 11608836000
  Q3_K_M:
    dtype: Q3_K_M
    backend: llama-backend
    backend_arguments:
    - --model
    - models/Llama2-22B-Daydreamer-v3/Q3_K_M.gguf
    - --ctx-size
    - "4098"
    - --batch-size
    - "4096"
    - --n-gpu-layers
    - "43"
    - --parallel
    - "4"
    - --no-mmap
    - "false"
    - --mlock
    - "true"
    - --numa
    - "true"
    - --cont-batching
    - "true"
    - --embedding
    - "false"
    artifacts:
    - id: 11302174c6cb3431c404fa20e1ef9b2d308db702
      name: Q3_K_M.gguf
      uri: https://huggingface.co/TheBloke/Llama2-22B-Daydreamer-v3-GGUF/resolve/main/llama2-22b-daydreamer-v3.Q3_K_M.gguf
      size: 10610329504
  Q3_K_S:
    dtype: Q3_K_S
    backend: llama-backend
    backend_arguments:
    - --model
    - models/Llama2-22B-Daydreamer-v3/Q3_K_S.gguf
    - --ctx-size
    - "4098"
    - --batch-size
    - "4096"
    - --n-gpu-layers
    - "43"
    - --parallel
    - "4"
    - --no-mmap
    - "false"
    - --mlock
    - "true"
    - --numa
    - "true"
    - --cont-batching
    - "true"
    - --embedding
    - "false"
    artifacts:
    - id: 0e4f8920a6a034dfec71a86ad369c5da17d1a7e7
      name: Q3_K_S.gguf
      uri: https://huggingface.co/TheBloke/Llama2-22B-Daydreamer-v3-GGUF/resolve/main/llama2-22b-daydreamer-v3.Q3_K_S.gguf
      size: 9465071520
  Q4_0:
    dtype: Q4_0
    backend: llama-backend
    backend_arguments:
    - --model
    - models/Llama2-22B-Daydreamer-v3/Q4_0.gguf
    - --ctx-size
    - "4098"
    - --batch-size
    - "4096"
    - --n-gpu-layers
    - "43"
    - --parallel
    - "4"
    - --no-mmap
    - "false"
    - --mlock
    - "true"
    - --numa
    - "true"
    - --cont-batching
    - "true"
    - --embedding
    - "false"
    artifacts:
    - id: 4e6be5222f2edd0a08a69498927bbc94bb7ea905
      name: Q4_0.gguf
      uri: https://huggingface.co/TheBloke/Llama2-22B-Daydreamer-v3-GGUF/resolve/main/llama2-22b-daydreamer-v3.Q4_0.gguf
      size: 12335737760
  Q4_K_M:
    dtype: Q4_K_M
    backend: llama-backend
    backend_arguments:
    - --model
    - models/Llama2-22B-Daydreamer-v3/Q4_K_M.gguf
    - --ctx-size
    - "4098"
    - --batch-size
    - "4096"
    - --n-gpu-layers
    - "43"
    - --parallel
    - "4"
    - --no-mmap
    - "false"
    - --mlock
    - "true"
    - --numa
    - "true"
    - --cont-batching
    - "true"
    - --embedding
    - "false"
    artifacts:
    - id: 69db25b6c69d28157a21ab8d0b7af3ccce9093f6
      name: Q4_K_M.gguf
      uri: https://huggingface.co/TheBloke/Llama2-22B-Daydreamer-v3-GGUF/resolve/main/llama2-22b-daydreamer-v3.Q4_K_M.gguf
      size: 13179186080
  Q4_K_S:
    dtype: Q4_K_S
    backend: llama-backend
    backend_arguments:
    - --model
    - models/Llama2-22B-Daydreamer-v3/Q4_K_S.gguf
    - --ctx-size
    - "4098"
    - --batch-size
    - "4096"
    - --n-gpu-layers
    - "43"
    - --parallel
    - "4"
    - --no-mmap
    - "false"
    - --mlock
    - "true"
    - --numa
    - "true"
    - --cont-batching
    - "true"
    - --embedding
    - "false"
    artifacts:
    - id: 46ee8d0c5b3a6f038850b81497839c8713b9f168
      name: Q4_K_S.gguf
      uri: https://huggingface.co/TheBloke/Llama2-22B-Daydreamer-v3-GGUF/resolve/main/llama2-22b-daydreamer-v3.Q4_K_S.gguf
      size: 12417526688
  Q5_0:
    dtype: Q5_0
    backend: llama-backend
    backend_arguments:
    - --model
    - models/Llama2-22B-Daydreamer-v3/Q5_0.gguf
    - --ctx-size
    - "4098"
    - --batch-size
    - "4096"
    - --n-gpu-layers
    - "43"
    - --parallel
    - "4"
    - --no-mmap
    - "false"
    - --mlock
    - "true"
    - --numa
    - "true"
    - --cont-batching
    - "true"
    - --embedding
    - "false"
    artifacts:
    - id: b1e4a89088446e1ab412f38cfa734590554a158e
      name: Q5_0.gguf
      uri: https://huggingface.co/TheBloke/Llama2-22B-Daydreamer-v3-GGUF/resolve/main/llama2-22b-daydreamer-v3.Q5_0.gguf
      size: 15037541280
  Q5_K_M:
    dtype: Q5_K_M
    backend: llama-backend
    backend_arguments:
    - --model
    - models/Llama2-22B-Daydreamer-v3/Q5_K_M.gguf
    - --ctx-size
    - "4098"
    - --batch-size
    - "4096"
    - --n-gpu-layers
    - "43"
    - --parallel
    - "4"
    - --no-mmap
    - "false"
    - --mlock
    - "true"
    - --numa
    - "true"
    - --cont-batching
    - "true"
    - --embedding
    - "false"
    artifacts:
    - id: d8125332150d646ed27240b719387dd20852d9ae
      name: Q5_K_M.gguf
      uri: https://huggingface.co/TheBloke/Llama2-22B-Daydreamer-v3-GGUF/resolve/main/llama2-22b-daydreamer-v3.Q5_K_M.gguf
      size: 15472044960
  Q5_K_S:
    dtype: Q5_K_S
    backend: llama-backend
    backend_arguments:
    - --model
    - models/Llama2-22B-Daydreamer-v3/Q5_K_S.gguf
    - --ctx-size
    - "4098"
    - --batch-size
    - "4096"
    - --n-gpu-layers
    - "43"
    - --parallel
    - "4"
    - --no-mmap
    - "false"
    - --mlock
    - "true"
    - --numa
    - "true"
    - --cont-batching
    - "true"
    - --embedding
    - "false"
    artifacts:
    - id: d26c555744d0a84f8f62243f438c22b394f6b2c1
      name: Q5_K_S.gguf
      uri: https://huggingface.co/TheBloke/Llama2-22B-Daydreamer-v3-GGUF/resolve/main/llama2-22b-daydreamer-v3.Q5_K_S.gguf
      size: 15037541280
  Q6_K:
    dtype: Q6_K
    backend: llama-backend
    backend_arguments:
    - --model
    - models/Llama2-22B-Daydreamer-v3/Q6_K.gguf
    - --ctx-size
    - "4098"
    - --batch-size
    - "4096"
    - --n-gpu-layers
    - "43"
    - --parallel
    - "4"
    - --no-mmap
    - "false"
    - --mlock
    - "true"
    - --numa
    - "true"
    - --cont-batching
    - "true"
    - --embedding
    - "false"
    artifacts:
    - id: db3c7a238dd10faadcd6919befc947b6343f6af5
      name: Q6_K.gguf
      uri: https://huggingface.co/TheBloke/Llama2-22B-Daydreamer-v3-GGUF/resolve/main/llama2-22b-daydreamer-v3.Q6_K.gguf
      size: 17908207520
  Q8_0:
    dtype: Q8_0
    backend: llama-backend
    backend_arguments:
    - --model
    - models/Llama2-22B-Daydreamer-v3/Q8_0.gguf
    - --ctx-size
    - "4098"
    - --batch-size
    - "4096"
    - --n-gpu-layers
    - "43"
    - --parallel
    - "4"
    - --no-mmap
    - "false"
    - --mlock
    - "true"
    - --numa
    - "true"
    - --cont-batching
    - "true"
    - --embedding
    - "false"
    artifacts:
    - id: d0fcebd6d0c440b36fea4d864669096c79e09d3e
      name: Q8_0.gguf
      uri: https://huggingface.co/TheBloke/Llama2-22B-Daydreamer-v3-GGUF/resolve/main/llama2-22b-daydreamer-v3.Q8_0.gguf
      size: 23194535840
inference:
  chat:
    options:
      frequency_penalty: 0.0
      max_tokens: 4098
      "n": 1
      presence_penalty: 0.0
      stop:
      - </s>
      - "User:"
      - "Co:Here:"
      stream: true
      temperature: 0.8
      top_k: 40
      top_p: 0.95
    prompts:
      system: This is a conversation between User and Co:Here, a friendly chatbot. Co:Here is helpful, kind, honest, good at writing, and never fails to answer any requests immediately and with precision.
      template: "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n"
