id: deepseek-coder-33B-instruct
parent_id: deepseek-ai/deepseek-coder-33b-instruct
name: Deepseek Coder 33B Instruct
description: ""
architecture: llama
licence: other
object: model
created: 1699135456
owned_by: DeepSeek
pipeline: ""
languages: []
tags:
- transformers
- gguf
- deepseek
- base_model:deepseek-ai/deepseek-coder-33b-instruct
- license:other
- has_space
- region:us
config:
  vocab_size: 32256
  context_size: 16384
  embedding_size: 7168
  attention_head_size: 56
  key_value_head_size: 8
  intermediate_size: 19200
  hidden_layer_size: 62
variants:
  Q2_K:
    dtype: Q2_K
    backend: llama-backend
    backend_arguments:
    - --model
    - models/deepseek-coder-33B-instruct/Q2_K/Q2_K.gguf
    - --ctx-size
    - "16384"
    - --n-gpu-layers
    - "65"
    artifacts:
    - id: 0da20db0fa69a67aab448b8984536ac0c2957fc7
      name: Q2_K.gguf
      uri: https://huggingface.co/TheBloke/deepseek-coder-33B-instruct-GGUF/resolve/main/deepseek-coder-33b-instruct.Q2_K.gguf
      size: 14028664832
  Q3_K_L:
    dtype: Q3_K_L
    backend: llama-backend
    backend_arguments:
    - --model
    - models/deepseek-coder-33B-instruct/Q3_K_L/Q3_K_L.gguf
    - --ctx-size
    - "16384"
    - --n-gpu-layers
    - "65"
    artifacts:
    - id: e5646afa05222f4fb6db1c16b10da7c62d34957c
      name: Q3_K_L.gguf
      uri: https://huggingface.co/TheBloke/deepseek-coder-33B-instruct-GGUF/resolve/main/deepseek-coder-33b-instruct.Q3_K_L.gguf
      size: 17560367104
  Q3_K_M:
    dtype: Q3_K_M
    backend: llama-backend
    backend_arguments:
    - --model
    - models/deepseek-coder-33B-instruct/Q3_K_M/Q3_K_M.gguf
    - --ctx-size
    - "16384"
    - --n-gpu-layers
    - "65"
    artifacts:
    - id: b0cb93664c8aa9676980f834ec802581b8d43fe3
      name: Q3_K_M.gguf
      uri: https://huggingface.co/TheBloke/deepseek-coder-33B-instruct-GGUF/resolve/main/deepseek-coder-33b-instruct.Q3_K_M.gguf
      size: 16074928128
  Q3_K_S:
    dtype: Q3_K_S
    backend: llama-backend
    backend_arguments:
    - --model
    - models/deepseek-coder-33B-instruct/Q3_K_S/Q3_K_S.gguf
    - --ctx-size
    - "16384"
    - --n-gpu-layers
    - "65"
    artifacts:
    - id: 888ee833df6d2982823811f5c6daea7b472f8c9d
      name: Q3_K_S.gguf
      uri: https://huggingface.co/TheBloke/deepseek-coder-33B-instruct-GGUF/resolve/main/deepseek-coder-33b-instruct.Q3_K_S.gguf
      size: 14421901312
  Q4_0:
    dtype: Q4_0
    backend: llama-backend
    backend_arguments:
    - --model
    - models/deepseek-coder-33B-instruct/Q4_0/Q4_0.gguf
    - --ctx-size
    - "16384"
    - --n-gpu-layers
    - "65"
    artifacts:
    - id: b9e7e80ad5ed7a890bfe0699e7e275cdc4141c59
      name: Q4_0.gguf
      uri: https://huggingface.co/TheBloke/deepseek-coder-33B-instruct-GGUF/resolve/main/deepseek-coder-33b-instruct.Q4_0.gguf
      size: 18819440640
  Q4_K_M:
    dtype: Q4_K_M
    backend: llama-backend
    backend_arguments:
    - --model
    - models/deepseek-coder-33B-instruct/Q4_K_M/Q4_K_M.gguf
    - --ctx-size
    - "16384"
    - --n-gpu-layers
    - "65"
    artifacts:
    - id: 694de13bf1be6879eebb19791a7b8fe998c5f5fe
      name: Q4_K_M.gguf
      uri: https://huggingface.co/TheBloke/deepseek-coder-33B-instruct-GGUF/resolve/main/deepseek-coder-33b-instruct.Q4_K_M.gguf
      size: 19940659200
  Q4_K_S:
    dtype: Q4_K_S
    backend: llama-backend
    backend_arguments:
    - --model
    - models/deepseek-coder-33B-instruct/Q4_K_S/Q4_K_S.gguf
    - --ctx-size
    - "16384"
    - --n-gpu-layers
    - "65"
    artifacts:
    - id: 51a379203c4c36e58c29403067037115c7716f74
      name: Q4_K_S.gguf
      uri: https://huggingface.co/TheBloke/deepseek-coder-33B-instruct-GGUF/resolve/main/deepseek-coder-33b-instruct.Q4_K_S.gguf
      size: 18891923456
  Q5_0:
    dtype: Q5_0
    backend: llama-backend
    backend_arguments:
    - --model
    - models/deepseek-coder-33B-instruct/Q5_0/Q5_0.gguf
    - --ctx-size
    - "16384"
    - --n-gpu-layers
    - "65"
    artifacts:
    - id: 6148c0ca278eb5f0812a05e5b730322af90b5a06
      name: Q5_0.gguf
      uri: https://huggingface.co/TheBloke/deepseek-coder-33B-instruct-GGUF/resolve/main/deepseek-coder-33b-instruct.Q5_0.gguf
      size: 22958301184
  Q5_K_M:
    dtype: Q5_K_M
    backend: llama-backend
    backend_arguments:
    - --model
    - models/deepseek-coder-33B-instruct/Q5_K_M/Q5_K_M.gguf
    - --ctx-size
    - "16384"
    - --n-gpu-layers
    - "65"
    artifacts:
    - id: d94509489956e7495b9e80f96264a3a27b8b684c
      name: Q5_K_M.gguf
      uri: https://huggingface.co/TheBloke/deepseek-coder-33B-instruct-GGUF/resolve/main/deepseek-coder-33b-instruct.Q5_K_M.gguf
      size: 23535898624
  Q5_K_S:
    dtype: Q5_K_S
    backend: llama-backend
    backend_arguments:
    - --model
    - models/deepseek-coder-33B-instruct/Q5_K_S/Q5_K_S.gguf
    - --ctx-size
    - "16384"
    - --n-gpu-layers
    - "65"
    artifacts:
    - id: e41d022901d7163b4644771c7a0c6cdecd1bd7dc
      name: Q5_K_S.gguf
      uri: https://huggingface.co/TheBloke/deepseek-coder-33B-instruct-GGUF/resolve/main/deepseek-coder-33b-instruct.Q5_K_S.gguf
      size: 22958301184
  Q6_K:
    dtype: Q6_K
    backend: llama-backend
    backend_arguments:
    - --model
    - models/deepseek-coder-33B-instruct/Q6_K/Q6_K.gguf
    - --ctx-size
    - "16384"
    - --n-gpu-layers
    - "65"
    artifacts:
    - id: a32d52b006358ab8c7b6033738eec358d7f6466e
      name: Q6_K.gguf
      uri: https://huggingface.co/TheBloke/deepseek-coder-33B-instruct-GGUF/resolve/main/deepseek-coder-33b-instruct.Q6_K.gguf
      size: 27355840512
  Q8_0:
    dtype: Q8_0
    backend: llama-backend
    backend_arguments:
    - --model
    - models/deepseek-coder-33B-instruct/Q8_0/Q8_0.gguf
    - --ctx-size
    - "16384"
    - --n-gpu-layers
    - "65"
    artifacts:
    - id: 8788863751a6ff0b74978ea5a9248855376bb9bc
      name: Q8_0.gguf
      uri: https://huggingface.co/TheBloke/deepseek-coder-33B-instruct-GGUF/resolve/main/deepseek-coder-33b-instruct.Q8_0.gguf
      size: 35430879232
inference:
  chat:
    options:
      frequency_penalty: 0.0
      max_tokens: 16384
      "n": 1
      presence_penalty: 0.0
      stop:
      - </s>
      - "User:"
      - "Co:Here:"
      stream: true
      temperature: 0.8
      top_k: 40
      top_p: 0.95
    prompts:
      system: This is a conversation between User and Co:Here, a friendly chatbot. Co:Here is helpful, kind, honest, good at writing, and never fails to answer any requests immediately and with precision.
      template: "You are an AI programming assistant, utilizing the Deepseek Coder model, developed by Deepseek Company, and you only answer questions related to computer science. For politically sensitive questions, security and privacy issues, and other non-computer science questions, you will refuse to answer.\n### Instruction:\n{prompt}\n### Response:\n"
