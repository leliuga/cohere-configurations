id: openchat-3.5-1210/Q5_K_M
parent_id: openchat/openchat-3.5-1210
name: Openchat 3.5 1210
description: ""
architecture: mistral
licence: apache-2.0
object: model
owned_by: OpenChat
artifact: https://huggingface.co/TheBloke/openchat-3.5-1210-GGUF/resolve/main/openchat-3.5-1210.Q5_K_M.gguf
pipeline: text-generation
languages: []
tags:
- transformers
- gguf
- mistral
- openchat
- C-RLFT
- text-generation
- dataset:openchat/openchat_sharegpt4_dataset
- dataset:kaist-ai/Feedback-Collection
- dataset:imone/OpenOrca_FLAN
- dataset:LDJnr/LessWrong-Amplify-Instruct
- dataset:LDJnr/Pure-Dove
- dataset:LDJnr/Verified-Camel
- dataset:tiedong/goat
- dataset:glaiveai/glaive-code-assistant
- dataset:meta-math/MetaMathQA
- dataset:OpenAssistant/oasst_top1_2023-08-25
- dataset:TIGER-Lab/MathInstruct
- arxiv:2309.11235
- arxiv:2303.08774
- arxiv:2212.10560
- base_model:openchat/openchat-3.5-1210
- license:apache-2.0
- text-generation-inference
- region:us
dtype: Q5_K_M
file_size: 5131421792
params_size: ""
vocab_size: 32002
context_size: 8192
embedding_size: 4096
pretrained: false
finetuned: false
quantized: true
backend: llama-backend
chat_options:
  cache_prompt: true
  frequency_penalty: 0.0
  grammar: ""
  ignore_eos: false
  mirostat: 0
  mirostat_eta: 0.1
  mirostat_tau: 5.0
  n_keep: -1
  n_predict: -1
  n_probs: 0
  penalize_nl: true
  presence_penalty: 0.0
  repeat_last_n: 64
  repeat_penalty: 1.1
  seed: -1
  temperature: 0.8
  tfs_z: 1.0
  top_k: 40
  top_p: 0.95
  typical_p: 1.0
prompt:
  system: This is a conversation between User and Co:Here, a friendly chatbot. Co:Here is helpful, kind, honest, good at writing, and never fails to answer any requests immediately and with precision.
  template: "GPT4 Correct User: {prompt}<|end_of_turn|>GPT4 Correct Assistant:\n"
