id: bagel-dpo-7B-v0.1/Q5_K_M
parent_id: jondurbin/bagel-dpo-7b-v0.1
name: Bagel DPO 7B v0.1
description: ""
architecture: mistral
licence: apache-2.0
object: model
owned_by: Jon Durbin
artifact: https://huggingface.co/TheBloke/bagel-dpo-7B-v0.1-GGUF/resolve/main/bagel-dpo-7b-v0.1.Q5_K_M.gguf
pipeline: ""
languages: []
tags:
- transformers
- gguf
- mistral
- dataset:ai2_arc
- dataset:unalignment/spicy-3.1
- dataset:codeparrot/apps
- dataset:facebook/belebele
- dataset:boolq
- dataset:jondurbin/cinematika-v0.1
- dataset:drop
- dataset:lmsys/lmsys-chat-1m
- dataset:TIGER-Lab/MathInstruct
- dataset:cais/mmlu
- dataset:Muennighoff/natural-instructions
- dataset:openbookqa
- dataset:piqa
- dataset:Vezora/Tested-22k-Python-Alpaca
- dataset:cakiki/rosetta-code
- dataset:Open-Orca/SlimOrca
- dataset:spider
- dataset:squad_v2
- dataset:migtissera/Synthia-v1.3
- dataset:datasets/winogrande
- dataset:nvidia/HelpSteer
- dataset:Intel/orca_dpo_pairs
- dataset:unalignment/toxic-dpo-v0.1
- dataset:jondurbin/truthy-dpo-v0.1
- dataset:allenai/ultrafeedback_binarized_cleaned
- base_model:jondurbin/bagel-dpo-7b-v0.1
- license:apache-2.0
- text-generation-inference
- region:us
dtype: Q5_K_M
file_size: 5131409664
params_size: ""
vocab_size: 32000
context_size: 32768
embedding_size: 4096
pretrained: false
finetuned: false
quantized: true
backend: llama-backend
chat_options:
  cache_prompt: true
  frequency_penalty: 0.0
  grammar: ""
  ignore_eos: false
  mirostat: 0
  mirostat_eta: 0.1
  mirostat_tau: 5.0
  n_keep: -1
  n_predict: -1
  n_probs: 0
  penalize_nl: true
  presence_penalty: 0.0
  repeat_last_n: 64
  repeat_penalty: 1.1
  seed: -1
  temperature: 0.8
  tfs_z: 1.0
  top_k: 40
  top_p: 0.95
  typical_p: 1.0
prompt:
  system: This is a conversation between User and Co:Here, a friendly chatbot. Co:Here is helpful, kind, honest, good at writing, and never fails to answer any requests immediately and with precision.
  template: "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\n{prompt}\n\n### Response:\n"
