id: Everyone-Coder-33B-Base
parent_id: rombodawg/Everyone-Coder-33b-Base
name: Everyone Coder 33B Base
description: ""
architecture: llama
licence: other
object: model
owned_by: rombo dawg
pipeline: ""
languages: []
tags:
- transformers
- gguf
- deepseek
- merge
- base_model:rombodawg/Everyone-Coder-33b-Base
- license:other
- region:us
config:
  vocab_size: 32256
  context_size: 16384
  embedding_size: 7168
  attention_head_size: 56
  key_value_head_size: 8
  intermediate_size: 19200
  hidden_layer_size: 62
variants:
  Q2_K:
    dtype: Q2_K
    backend: llama-backend
    backend_arguments:
    - --model
    - models/Everyone-Coder-33B-Base/Q2_K/Q2_K.gguf
    - --ctx-size
    - "16384"
    - --n-gpu-layers
    - "65"
    artifacts:
    - id: 958f7578ae51f3295f02dd26faa81f64526d5593
      name: Q2_K.gguf
      uri: https://huggingface.co/TheBloke/Everyone-Coder-33B-Base-GGUF/resolve/main/everyone-coder-33b-base.Q2_K.gguf
      size: 12355884192
  Q3_K_L:
    dtype: Q3_K_L
    backend: llama-backend
    backend_arguments:
    - --model
    - models/Everyone-Coder-33B-Base/Q3_K_L/Q3_K_L.gguf
    - --ctx-size
    - "16384"
    - --n-gpu-layers
    - "65"
    artifacts:
    - id: fb45f001280fd611d8836e9ba37e7c274c2a7ec4
      name: Q3_K_L.gguf
      uri: https://huggingface.co/TheBloke/Everyone-Coder-33B-Base-GGUF/resolve/main/everyone-coder-33b-base.Q3_K_L.gguf
      size: 17560368288
  Q3_K_M:
    dtype: Q3_K_M
    backend: llama-backend
    backend_arguments:
    - --model
    - models/Everyone-Coder-33B-Base/Q3_K_M/Q3_K_M.gguf
    - --ctx-size
    - "16384"
    - --n-gpu-layers
    - "65"
    artifacts:
    - id: c9102eea98c37ec6eadf03f74abe26eec536f939
      name: Q3_K_M.gguf
      uri: https://huggingface.co/TheBloke/Everyone-Coder-33B-Base-GGUF/resolve/main/everyone-coder-33b-base.Q3_K_M.gguf
      size: 16092132512
  Q3_K_S:
    dtype: Q3_K_S
    backend: llama-backend
    backend_arguments:
    - --model
    - models/Everyone-Coder-33B-Base/Q3_K_S/Q3_K_S.gguf
    - --ctx-size
    - "16384"
    - --n-gpu-layers
    - "65"
    artifacts:
    - id: d873b79a3a6a269bf0c18549811b26d7fde1bcc1
      name: Q3_K_S.gguf
      uri: https://huggingface.co/TheBloke/Everyone-Coder-33B-Base-GGUF/resolve/main/everyone-coder-33b-base.Q3_K_S.gguf
      size: 14421902496
  Q4_0:
    dtype: Q4_0
    backend: llama-backend
    backend_arguments:
    - --model
    - models/Everyone-Coder-33B-Base/Q4_0/Q4_0.gguf
    - --ctx-size
    - "16384"
    - --n-gpu-layers
    - "65"
    artifacts:
    - id: 82813a0a30c55a3938dc31afd5a3b766f8eb6d24
      name: Q4_0.gguf
      uri: https://huggingface.co/TheBloke/Everyone-Coder-33B-Base-GGUF/resolve/main/everyone-coder-33b-base.Q4_0.gguf
      size: 18819441824
  Q4_K_M:
    dtype: Q4_K_M
    backend: llama-backend
    backend_arguments:
    - --model
    - models/Everyone-Coder-33B-Base/Q4_K_M/Q4_K_M.gguf
    - --ctx-size
    - "16384"
    - --n-gpu-layers
    - "65"
    artifacts:
    - id: e2504a217185e2069107c5e320808b85637ea824
      name: Q4_K_M.gguf
      uri: https://huggingface.co/TheBloke/Everyone-Coder-33B-Base-GGUF/resolve/main/everyone-coder-33b-base.Q4_K_M.gguf
      size: 19940660384
  Q4_K_S:
    dtype: Q4_K_S
    backend: llama-backend
    backend_arguments:
    - --model
    - models/Everyone-Coder-33B-Base/Q4_K_S/Q4_K_S.gguf
    - --ctx-size
    - "16384"
    - --n-gpu-layers
    - "65"
    artifacts:
    - id: d1dbf55bf5faecb75c571a1baaa68648d6ea3d00
      name: Q4_K_S.gguf
      uri: https://huggingface.co/TheBloke/Everyone-Coder-33B-Base-GGUF/resolve/main/everyone-coder-33b-base.Q4_K_S.gguf
      size: 18943534240
  Q5_0:
    dtype: Q5_0
    backend: llama-backend
    backend_arguments:
    - --model
    - models/Everyone-Coder-33B-Base/Q5_0/Q5_0.gguf
    - --ctx-size
    - "16384"
    - --n-gpu-layers
    - "65"
    artifacts:
    - id: 1e25253e970e68b1d86925683dc4f7aba183a6e8
      name: Q5_0.gguf
      uri: https://huggingface.co/TheBloke/Everyone-Coder-33B-Base-GGUF/resolve/main/everyone-coder-33b-base.Q5_0.gguf
      size: 22958302368
  Q5_K_M:
    dtype: Q5_K_M
    backend: llama-backend
    backend_arguments:
    - --model
    - models/Everyone-Coder-33B-Base/Q5_K_M/Q5_K_M.gguf
    - --ctx-size
    - "16384"
    - --n-gpu-layers
    - "65"
    artifacts:
    - id: 985567ac752de52e079965f1fa1aab00854761d8
      name: Q5_K_M.gguf
      uri: https://huggingface.co/TheBloke/Everyone-Coder-33B-Base-GGUF/resolve/main/everyone-coder-33b-base.Q5_K_M.gguf
      size: 23535899808
  Q5_K_S:
    dtype: Q5_K_S
    backend: llama-backend
    backend_arguments:
    - --model
    - models/Everyone-Coder-33B-Base/Q5_K_S/Q5_K_S.gguf
    - --ctx-size
    - "16384"
    - --n-gpu-layers
    - "65"
    artifacts:
    - id: 948321ebcc8dcd781b3e64bea69b3a66e945590d
      name: Q5_K_S.gguf
      uri: https://huggingface.co/TheBloke/Everyone-Coder-33B-Base-GGUF/resolve/main/everyone-coder-33b-base.Q5_K_S.gguf
      size: 22958302368
  Q6_K:
    dtype: Q6_K
    backend: llama-backend
    backend_arguments:
    - --model
    - models/Everyone-Coder-33B-Base/Q6_K/Q6_K.gguf
    - --ctx-size
    - "16384"
    - --n-gpu-layers
    - "65"
    artifacts:
    - id: b38e0c2591f71167d4329d316163529124419a6c
      name: Q6_K.gguf
      uri: https://huggingface.co/TheBloke/Everyone-Coder-33B-Base-GGUF/resolve/main/everyone-coder-33b-base.Q6_K.gguf
      size: 27355841696
  Q8_0:
    dtype: Q8_0
    backend: llama-backend
    backend_arguments:
    - --model
    - models/Everyone-Coder-33B-Base/Q8_0/Q8_0.gguf
    - --ctx-size
    - "16384"
    - --n-gpu-layers
    - "65"
    artifacts:
    - id: 810fb7b15f373f57636fd99034e2a71c7f6fb728
      name: Q8_0.gguf
      uri: https://huggingface.co/TheBloke/Everyone-Coder-33B-Base-GGUF/resolve/main/everyone-coder-33b-base.Q8_0.gguf
      size: 35430880416
inference:
  chat:
    options:
      frequency_penalty: 0.0
      max_tokens: 16384
      "n": 1
      presence_penalty: 0.0
      stop:
      - </s>
      - "User:"
      - "Co:Here:"
      stream: true
      temperature: 0.8
      top_k: 40
      top_p: 0.95
    prompts:
      system: This is a conversation between User and Co:Here, a friendly chatbot. Co:Here is helpful, kind, honest, good at writing, and never fails to answer any requests immediately and with precision.
      template: "{prompt}\n"
