---
license: apache-2.0
---

# Chupacabra-8x7B-experts 
# Mixtral-8x7b-experts merge, of Chupacabra, OpenChat, Falkor, and Starling-LM

<p><img src="https://huggingface.co/perlthoughts/Chupacabra-7B/resolve/main/chupacabra7b%202.png" width=330></p>

### Model Description

Special thanks to @cgt123 for his great work on https://github.com/cg123/mergekit.

This was made using the 'mixtral' branch on the mergekit repo.

#OneManArmy

### More Info

- **Developed by:** Ray Hernandez
- **Model type:** Mistral
- **Language(s) (NLP):** English
- **License:** Apache 2.0

